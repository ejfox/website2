1 Text, 2 Text
"Why must forecast evaluation be out-of-sample?","In-sample fit always improves with more parameters (overfitting). True test: does model predict data it hasn't seen? Split data temporally: train on past, test on future. Never test on training data."
"What is RMSE (Root Mean Squared Error)?","√(mean of squared errors). Penalizes large errors heavily. In same units as forecast variable. Lower = better. RMSE = 5% for volatility forecast means typical error is 5 percentage points."
"What is MAE (Mean Absolute Error)?","Mean of |actual - forecast|. Less sensitive to outliers than RMSE. In same units. If RMSE >> MAE, you have occasional large errors. MAE more robust for heavy-tailed errors."
"What is MAPE (Mean Absolute Percentage Error)?","Mean of |error / actual| × 100. Scale-independent—useful for comparing across different series. But: undefined when actual = 0, asymmetric (underestimates penalized more). Use sMAPE for symmetry."
"What is directional accuracy?","Fraction of times forecast got the direction right. For returns: did you predict up when it went up? 50% = random guessing. Important for trading signals even if magnitude is wrong."
"What is the Diebold-Mariano test?","Test whether two forecasts have significantly different accuracy. H0: equal accuracy. Accounts for autocorrelation in forecast errors. p < 0.05: one forecast is statistically better."
"What is a Mincer-Zarnowitz regression?","Regress actual on forecast: Actual = α + β × Forecast + ε. Ideal: α=0, β=1 (unbiased, correct scaling). If α≠0: bias. If β≠1: under/overreaction. Joint F-test for rationality."
"Why does forecast combination often work?","Different models capture different patterns. Errors partially cancel. Simple average often beats complex weighting. 'Wisdom of crowds' for forecasts. Robust to model misspecification."
"What is the forecast combination puzzle?","Simple averages often beat sophisticated optimal combination weights. Estimated weights have estimation error that can hurt. Start with equal weights; only get fancy with lots of data."
"What is forecast encompassing?","Test whether one forecast contains all useful information. If forecast A 'encompasses' B, then B adds nothing beyond A. Formally: regress actual on A and B; B's coefficient should be zero if A encompasses it."
"What is QLIKE loss for volatility forecasting?","QLIKE = log(σ²) + realized²/σ². Robust loss function for volatility. Unlike MSE, doesn't favor systematically under-predicting volatility. Standard for volatility forecast evaluation."
"What is a forecast interval vs point forecast?","Point forecast: single number (tomorrow's price is $100). Interval: range with probability (90% CI: $95-$105). Intervals convey uncertainty. Evaluate with coverage: is 90% CI right 90% of the time?"
"What is the efficient market hypothesis for forecasting?","If markets are efficient, prices incorporate all information. Returns should be unpredictable. Beating buy-and-hold is hard. Modest predictability exists but may not survive transaction costs."
"What is forecast evaluation in real-time?","Use data available AT THE TIME of forecast. GDP is revised; use first release, not final. Avoids look-ahead bias. More realistic assessment of what forecaster could have known."
"What is the random walk benchmark?","Forecast = last observation (tomorrow = today). Hard to beat for financial returns, exchange rates. If your model can't beat random walk, it's adding no value. Start with this baseline."
