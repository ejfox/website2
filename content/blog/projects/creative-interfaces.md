---
title: "Creative Interfaces & Digital Art"
date: 2024-07-01T00:00:00-04:00
modified: 2025-08-13T11:46:54-04:00
tech: ["Computer Vision", "MIDI", "WebGL", "Hand Tracking", "Generative Art", "Interactive Media"]
state: deployed
aiInvolvement: ai-assisted
---

These are my attempts to make computers that respond to the way humans actually move and gestureâ€”exploring the design space between human intuition and machine capability. Each project pushes beyond traditional HCI constraints to find new interaction models. Some of these work better than others, but they all represent steps toward interfaces that feel more like extensions of thought than barriers to it.

## Projects

1. [hand-midi-controller](https://github.com/ejfox/hand-midi-controller): Professional hand tracking MIDI controller with TouchDesigner integration. Converts hand movements to MIDI with detailed performance timing breakdowns and memory analysis for creative interface exploration.
2. [handtrack-websockets](https://github.com/ejfox/handtrack-websockets): Real-time gesture streaming pushing the boundaries of browser-based interaction.
3. [flipper-generative-art](https://github.com/ejfox/flipper-generative-art): Real-time generative art and animated patterns for Flipper Zero with 10 gradient types, Floyd-Steinberg dithering, and smooth 30 FPS animations. Finding art within the constraints of 64KB RAM.
4. [ps5-tmux](https://github.com/ejfox/ps5-tmux) is a little tool to make it easier to vibe-code; just move between panes with your PS5 controller and accept changes with the X button, or hit the middle button to enter dictation mode.