{
  "content": "",
  "html": "",
  "title": "How To Give an LLM As Much Context In As Little Tokens As Possible",
  "metadata": {
    "dek": "In which, in the pursuit of intelligent answers, we try to give the robot as much information about the world as possible very few words",
    "inprogress": true,
    "date": "2023-08-07T13:28:25.000Z",
    "modified": "2023-09-09T18:58:15.000Z",
    "tags": "machinelearning programming howto",
    "hidden": true,
    "draft": true,
    "words": 16,
    "images": 0,
    "links": 0,
    "codeBlocks": 0,
    "headers": {
      "h1": 1
    },
    "toc": [
      {
        "text": "How To Give an LLM As Much Context In As Little Tokens As Possible",
        "slug": "how-to-give-an-llm-as-much-context-in-as-little-tokens-as-possible",
        "level": "h1",
        "children": []
      }
    ],
    "type": "post",
    "sourcePath": "../../../../../code/website2/content/blog/drafts/compressing-information-for-llm-context.md",
    "sourceDir": "/Users/ejfox/Library/Mobile Documents/iCloud~md~obsidian/Documents/ejfox/"
  }
}