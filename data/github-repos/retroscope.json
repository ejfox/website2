{
  "name": "retroscope",
  "description": "Use an AI to generate text descriptions of all your screenshots in Cloudinary",
  "url": "https://github.com/ejfox/retroscope",
  "homepage": null,
  "stats": {
    "stars": 0,
    "forks": 0,
    "watchers": 1,
    "openIssues": 0
  },
  "language": "JavaScript",
  "languageColor": "#f1e05a",
  "languages": {
    "JavaScript": 75455,
    "Dockerfile": 645
  },
  "diskUsage": 154,
  "topics": [],
  "readme": {
    "html": "<h1 id=\"Ô∏è-retroscope-\">üëÅÔ∏è RETROSCOPE üì∏</h1>\n<pre><code> ____      _                                      \n|  _ \\ ___| |_ _ __ ___  ___  ___ ___  _ __  ___ \n| |_) / _ \\ __| '__/ _ \\/ __|/ __/ _ \\| '_ \\/ __|\n|  _ &lt;  __/ |_| | | (_) \\__ \\ (_| (_) | |_) \\__ \\\n|_| \\_\\___|\\__|_|  \\___/|___/\\___\\___/| .__/|___/\n                                      |_|         \n</code></pre>\n<p>AI-powered image analysis tool that processes images from Cloudinary using Google's Gemini Vision API to generate detailed descriptions. Handles both screenshots and photographs intelligently.</p>\n<h2 id=\"features\">Features</h2>\n<ul>\n<li>Analyzes screenshots with focus on UI/functionality and exact text capture</li>\n<li>Processes photographs with focus on composition and visual details</li>\n<li>Stores descriptions in Cloudinary metadata</li>\n<li>Smart token usage (16K for screenshots, 32K for photos)</li>\n<li>Detailed cost tracking (~1.7¬¢ per image)</li>\n<li>Rate limiting and pagination handling</li>\n</ul>\n<h2 id=\"installation\">Installation</h2>\n<pre><code class=\"language-bash\"># Clone and install\ngit clone https://github.com/yourusername/retroscope.git\ncd retroscope\nnpm install\n\n# Copy and configure environment variables\ncp .env.example .env\n</code></pre>\n<h2 id=\"docker-deployment\">Docker Deployment</h2>\n<p>The application can be run in a Docker container with automated scheduling. This is the recommended way to deploy Retroscope in production.</p>\n<h3 id=\"prerequisites\">Prerequisites</h3>\n<ul>\n<li>Docker</li>\n<li>Docker Compose v2.x or higher</li>\n</ul>\n<h3 id=\"setup\">Setup</h3>\n<ol>\n<li>Clone the repository and configure environment:</li>\n</ol>\n<pre><code class=\"language-bash\">git clone https://github.com/yourusername/retroscope.git\ncd retroscope\ncp .env.example .env\n</code></pre>\n<ol>\n<li>Edit <code>.env</code> with your credentials:</li>\n</ol>\n<pre><code class=\"language-env\">CLOUDINARY_CLOUD_NAME=your_cloud_name\nCLOUDINARY_API_KEY=your_api_key\nCLOUDINARY_API_SECRET=your_api_secret\nGOOGLE_API_KEY=your_gemini_api_key\n</code></pre>\n<ol>\n<li>Start the containers:</li>\n</ol>\n<pre><code class=\"language-bash\"># Build and start in detached mode\ndocker compose up -d --build\n\n# Verify containers are running and healthy\ndocker compose ps\n</code></pre>\n<p>This will start two containers:</p>\n<ul>\n<li><code>retroscope</code>: The main application container with health monitoring</li>\n<li><code>scheduler</code>: An Ofelia scheduler that runs the app on a schedule</li>\n</ul>\n<h3 id=\"production-configuration\">Production Configuration</h3>\n<p>The Docker setup includes several production-ready features:</p>\n<ul>\n<li><strong>Health Checks</strong>: Both containers are monitored for health status</li>\n<li><strong>Logging</strong>: JSON log files with rotation (100MB max size, 3 files kept)</li>\n<li><strong>Security</strong>: Non-root user in containers</li>\n<li><strong>Resource Management</strong>: Automatic container restarts on failure</li>\n<li><strong>Error Handling</strong>: Job overlap prevention and timeout settings</li>\n</ul>\n<h3 id=\"scheduling\">Scheduling</h3>\n<p>The application runs at 50 minutes past every hour by default, processing up to 100 images per run. Configuration is in <code>config/ofelia.ini</code>:</p>\n<pre><code class=\"language-ini\">[global]\nsmtp-host = \"\"  # Disable email notifications\n\n[job-exec \"process-images\"]\nschedule = 0 50 * * * *  # Run at 50 minutes past every hour\ncontainer = retroscope_retroscope_1\ncommand = npm start -- --n=100 --verbose\nno-overlap = true\non-error = \"continue\"\ntimeout = 45m  # Maximum runtime of 45 minutes\n</code></pre>\n<p>Common schedule patterns:</p>\n<ul>\n<li><code>0 50 * * * *</code>: Every hour at minute 50 (default)</li>\n<li><code>0 */30 * * * *</code>: Every 30 minutes</li>\n<li><code>0 0 */2 * * *</code>: Every 2 hours at minute 0</li>\n<li><code>0 0 0 * * *</code>: Once per day at midnight</li>\n</ul>\n<h3 id=\"monitoring\">Monitoring</h3>\n<p>Monitor the application's health and logs:</p>\n<pre><code class=\"language-bash\"># Check container health status\ndocker compose ps\n\n# View application logs\ndocker compose logs retroscope\n\n# View scheduler logs\ndocker compose logs scheduler\n\n# Follow all logs in real-time\ndocker compose logs -f\n\n# View specific container's last 100 lines\ndocker compose logs --tail=100 retroscope\n</code></pre>\n<h3 id=\"maintenance\">Maintenance</h3>\n<p>To update the application:</p>\n<pre><code class=\"language-bash\"># Pull latest changes\ngit pull\n\n# Rebuild and restart containers\ndocker compose down\ndocker compose up -d --build\n\n# Verify health\ndocker compose ps\n</code></pre>\n<p>To stop the application:</p>\n<pre><code class=\"language-bash\">docker compose down\n</code></pre>\n<p>For debugging:</p>\n<pre><code class=\"language-bash\"># View detailed container information\ndocker compose ps -a\n\n# Check container resource usage\ndocker stats\n\n# Enter container for debugging\ndocker compose exec retroscope /bin/bash\n</code></pre>\n<h2 id=\"environment-variables\">Environment Variables</h2>\n<pre><code class=\"language-env\">CLOUDINARY_CLOUD_NAME=your_cloud_name\nCLOUDINARY_API_KEY=your_api_key\nCLOUDINARY_API_SECRET=your_api_secret\nGOOGLE_API_KEY=your_gemini_api_key\n</code></pre>\n<h2 id=\"usage\">Usage</h2>\n<pre><code class=\"language-bash\"># Process 10 images\nnpm start -- --n=10\n\n# Process with verbose logging\nnpm start -- --n=10 --verbose\n\n# Force reprocess already analyzed images\nnpm start -- --n=10 --reprocess\n\n# Export all analyzed images\nnpm start -- --export\n\n# Export with date range\nnpm start -- --export --export-from=\"2024-01-01\" --export-to=\"2024-12-31\"\n</code></pre>\n<h2 id=\"accessing-ai-descriptions\">Accessing AI Descriptions</h2>\n<p>The AI-generated descriptions are stored in Cloudinary's metadata. Here's how to access them:</p>\n<pre><code class=\"language-javascript\">import { v2 as cloudinary } from 'cloudinary';\n\n// Initialize Cloudinary\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET,\n});\n\n// Fetch images with their AI descriptions\nasync function getAnalyzedImages() {\n  const images = [];\n  let nextCursor = null;\n\n  do {\n    const result = await new Promise((resolve, reject) =&gt; {\n      cloudinary.api.resources({\n        type: 'upload',\n        max_results: 500,\n        next_cursor: nextCursor,\n        tags: true,\n        context: true,  // Important: This gets the metadata\n      }, (error, result) =&gt; {\n        if (error) reject(error);\n        else resolve(result);\n      });\n    });\n\n    // Transform and filter images\n    const pageImages = result.resources\n      .filter(res =&gt; res.tags?.includes('ai_processed'))\n      .map(resource =&gt; ({\n        id: resource.public_id,\n        url: resource.secure_url,\n        created_at: resource.created_at,\n        // The AI description is stored here:\n        description: resource.context?.custom?.ai_description || null,\n        analyzed_at: resource.context?.custom?.updated_at || null,\n      }));\n\n    images.push(...pageImages);\n    nextCursor = result.next_cursor;\n  } while (nextCursor);\n\n  return images;\n}\n\n// Example usage:\nconst images = await getAnalyzedImages();\nconsole.log(`Found ${images.length} analyzed images`);\n</code></pre>\n<h3 id=\"cloudinary-metadata-structure\">Cloudinary Metadata Structure</h3>\n<p>The AI descriptions are stored in:</p>\n<ul>\n<li><code>context.custom.ai_description</code>: The full AI-generated description</li>\n<li><code>context.custom.updated_at</code>: Timestamp of the analysis</li>\n<li><code>tags</code>: Includes \"ai_processed\" for processed images</li>\n</ul>\n<p>Example response structure:</p>\n<pre><code class=\"language-javascript\">{\n  public_id: \"example_image\",\n  secure_url: \"https://...\",\n  context: {\n    custom: {\n      ai_description: \"Detailed analysis of the image...\",\n      updated_at: \"2024-01-02T02:44:10.158Z\"\n    }\n  },\n  tags: [\"ai_processed\"],\n  // ... other Cloudinary fields\n}\n</code></pre>\n<h2 id=\"license\">License</h2>\n<p>MIT</p>\n<h2 id=\"grafana-queries\">Grafana Queries</h2>\n<h3 id=\"cost-tracking\">Cost Tracking</h3>\n<pre><code class=\"language-logql\"># Total cost over time\nsum(rate({job=\"retroscope\"} |= \"METRIC:processing_cost\" | json | unwrap metric_value [1m]))\n\n# Average cost per image type\navg by (is_screenshot) (\n  {job=\"retroscope\"} |= \"METRIC:processing_cost\" \n  | json \n  | unwrap metric_value\n)\n</code></pre>\n<h3 id=\"processing-speed\">Processing Speed</h3>\n<pre><code class=\"language-logql\"># Images processed per minute\nsum(rate({job=\"retroscope\"} |= \"METRIC:images_per_second\" | json | unwrap metric_value [1m]))\n\n# Processing duration histogram\n{job=\"retroscope\"} |= \"METRIC:processing_speed\"\n| json\n| unwrap total_duration\n| histogram duration_seconds\n</code></pre>\n<h3 id=\"token-usage\">Token Usage</h3>\n<pre><code class=\"language-logql\"># Token usage by image type\nsum by (is_screenshot) (\n  {job=\"retroscope\"} |= \"METRIC:tokens_used\"\n  | json\n  | unwrap metric_value\n)\n\n# Average tokens per image over time\navg(rate({job=\"retroscope\"} |= \"METRIC:tokens_used\" | json | unwrap metric_value [5m]))\n</code></pre>\n<h3 id=\"error-tracking\">Error Tracking</h3>\n<pre><code class=\"language-logql\"># Error rate\nsum(rate({job=\"retroscope\", level=\"error\"} [5m]))\n\n# Failed images count\n{job=\"retroscope\"} |= \"METRIC:total_cost\"\n| json\n| unwrap failed_images\n</code></pre>\n<h3 id=\"success-rate\">Success Rate</h3>\n<pre><code class=\"language-logql\"># Successful vs failed processing ratio\nsum by (success) (\n  {job=\"retroscope\"} |= \"METRIC:processing_cost\"\n  | json\n  | unwrap metric_value\n)\n</code></pre>\n<p>These queries can be used to create dashboards showing:</p>\n<ul>\n<li>Cost per image/batch</li>\n<li>Processing speed and efficiency</li>\n<li>Token usage patterns</li>\n<li>Error rates and types</li>\n<li>Success/failure ratios</li>\n</ul>",
    "raw": "# üëÅÔ∏è RETROSCOPE üì∏\n\n```\n ____      _                                      \n|  _ \\ ___| |_ _ __ ___  ___  ___ ___  _ __  ___ \n| |_) / _ \\ __| '__/ _ \\/ __|/ __/ _ \\| '_ \\/ __|\n|  _ <  __/ |_| | | (_) \\__ \\ (_| (_) | |_) \\__ \\\n|_| \\_\\___|\\__|_|  \\___/|___/\\___\\___/| .__/|___/\n                                      |_|         \n```\n\nAI-powered image analysis tool that processes images from Cloudinary using Google's Gemini Vision API to generate detailed descriptions. Handles both screenshots and photographs intelligently.\n\n## Features\n\n- Analyzes screenshots with focus on UI/functionality and exact text capture\n- Processes photographs with focus on composition and visual details\n- Stores descriptions in Cloudinary metadata\n- Smart token usage (16K for screenshots, 32K for photos)\n- Detailed cost tracking (~1.7¬¢ per image)\n- Rate limiting and pagination handling\n\n## Installation\n\n```bash\n# Clone and install\ngit clone https://github.com/yourusername/retroscope.git\ncd retroscope\nnpm install\n\n# Copy and configure environment variables\ncp .env.example .env\n```\n\n## Docker Deployment\n\nThe application can be run in a Docker container with automated scheduling. This is the recommended way to deploy Retroscope in production.\n\n### Prerequisites\n\n- Docker\n- Docker Compose v2.x or higher\n\n### Setup\n\n1. Clone the repository and configure environment:\n```bash\ngit clone https://github.com/yourusername/retroscope.git\ncd retroscope\ncp .env.example .env\n```\n\n2. Edit `.env` with your credentials:\n```env\nCLOUDINARY_CLOUD_NAME=your_cloud_name\nCLOUDINARY_API_KEY=your_api_key\nCLOUDINARY_API_SECRET=your_api_secret\nGOOGLE_API_KEY=your_gemini_api_key\n```\n\n3. Start the containers:\n```bash\n# Build and start in detached mode\ndocker compose up -d --build\n\n# Verify containers are running and healthy\ndocker compose ps\n```\n\nThis will start two containers:\n- `retroscope`: The main application container with health monitoring\n- `scheduler`: An Ofelia scheduler that runs the app on a schedule\n\n### Production Configuration\n\nThe Docker setup includes several production-ready features:\n\n- **Health Checks**: Both containers are monitored for health status\n- **Logging**: JSON log files with rotation (100MB max size, 3 files kept)\n- **Security**: Non-root user in containers\n- **Resource Management**: Automatic container restarts on failure\n- **Error Handling**: Job overlap prevention and timeout settings\n\n### Scheduling\n\nThe application runs at 50 minutes past every hour by default, processing up to 100 images per run. Configuration is in `config/ofelia.ini`:\n\n```ini\n[global]\nsmtp-host = \"\"  # Disable email notifications\n\n[job-exec \"process-images\"]\nschedule = 0 50 * * * *  # Run at 50 minutes past every hour\ncontainer = retroscope_retroscope_1\ncommand = npm start -- --n=100 --verbose\nno-overlap = true\non-error = \"continue\"\ntimeout = 45m  # Maximum runtime of 45 minutes\n```\n\nCommon schedule patterns:\n- `0 50 * * * *`: Every hour at minute 50 (default)\n- `0 */30 * * * *`: Every 30 minutes\n- `0 0 */2 * * *`: Every 2 hours at minute 0\n- `0 0 0 * * *`: Once per day at midnight\n\n### Monitoring\n\nMonitor the application's health and logs:\n\n```bash\n# Check container health status\ndocker compose ps\n\n# View application logs\ndocker compose logs retroscope\n\n# View scheduler logs\ndocker compose logs scheduler\n\n# Follow all logs in real-time\ndocker compose logs -f\n\n# View specific container's last 100 lines\ndocker compose logs --tail=100 retroscope\n```\n\n### Maintenance\n\nTo update the application:\n\n```bash\n# Pull latest changes\ngit pull\n\n# Rebuild and restart containers\ndocker compose down\ndocker compose up -d --build\n\n# Verify health\ndocker compose ps\n```\n\nTo stop the application:\n```bash\ndocker compose down\n```\n\nFor debugging:\n```bash\n# View detailed container information\ndocker compose ps -a\n\n# Check container resource usage\ndocker stats\n\n# Enter container for debugging\ndocker compose exec retroscope /bin/bash\n```\n\n## Environment Variables\n\n```env\nCLOUDINARY_CLOUD_NAME=your_cloud_name\nCLOUDINARY_API_KEY=your_api_key\nCLOUDINARY_API_SECRET=your_api_secret\nGOOGLE_API_KEY=your_gemini_api_key\n```\n\n## Usage\n\n```bash\n# Process 10 images\nnpm start -- --n=10\n\n# Process with verbose logging\nnpm start -- --n=10 --verbose\n\n# Force reprocess already analyzed images\nnpm start -- --n=10 --reprocess\n\n# Export all analyzed images\nnpm start -- --export\n\n# Export with date range\nnpm start -- --export --export-from=\"2024-01-01\" --export-to=\"2024-12-31\"\n```\n\n## Accessing AI Descriptions\n\nThe AI-generated descriptions are stored in Cloudinary's metadata. Here's how to access them:\n\n```javascript\nimport { v2 as cloudinary } from 'cloudinary';\n\n// Initialize Cloudinary\ncloudinary.config({\n  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,\n  api_key: process.env.CLOUDINARY_API_KEY,\n  api_secret: process.env.CLOUDINARY_API_SECRET,\n});\n\n// Fetch images with their AI descriptions\nasync function getAnalyzedImages() {\n  const images = [];\n  let nextCursor = null;\n\n  do {\n    const result = await new Promise((resolve, reject) => {\n      cloudinary.api.resources({\n        type: 'upload',\n        max_results: 500,\n        next_cursor: nextCursor,\n        tags: true,\n        context: true,  // Important: This gets the metadata\n      }, (error, result) => {\n        if (error) reject(error);\n        else resolve(result);\n      });\n    });\n\n    // Transform and filter images\n    const pageImages = result.resources\n      .filter(res => res.tags?.includes('ai_processed'))\n      .map(resource => ({\n        id: resource.public_id,\n        url: resource.secure_url,\n        created_at: resource.created_at,\n        // The AI description is stored here:\n        description: resource.context?.custom?.ai_description || null,\n        analyzed_at: resource.context?.custom?.updated_at || null,\n      }));\n\n    images.push(...pageImages);\n    nextCursor = result.next_cursor;\n  } while (nextCursor);\n\n  return images;\n}\n\n// Example usage:\nconst images = await getAnalyzedImages();\nconsole.log(`Found ${images.length} analyzed images`);\n```\n\n### Cloudinary Metadata Structure\n\nThe AI descriptions are stored in:\n- `context.custom.ai_description`: The full AI-generated description\n- `context.custom.updated_at`: Timestamp of the analysis\n- `tags`: Includes \"ai_processed\" for processed images\n\nExample response structure:\n```javascript\n{\n  public_id: \"example_image\",\n  secure_url: \"https://...\",\n  context: {\n    custom: {\n      ai_description: \"Detailed analysis of the image...\",\n      updated_at: \"2024-01-02T02:44:10.158Z\"\n    }\n  },\n  tags: [\"ai_processed\"],\n  // ... other Cloudinary fields\n}\n```\n\n## License\n\nMIT\n\n## Grafana Queries\n\n### Cost Tracking\n```logql\n# Total cost over time\nsum(rate({job=\"retroscope\"} |= \"METRIC:processing_cost\" | json | unwrap metric_value [1m]))\n\n# Average cost per image type\navg by (is_screenshot) (\n  {job=\"retroscope\"} |= \"METRIC:processing_cost\" \n  | json \n  | unwrap metric_value\n)\n```\n\n### Processing Speed\n```logql\n# Images processed per minute\nsum(rate({job=\"retroscope\"} |= \"METRIC:images_per_second\" | json | unwrap metric_value [1m]))\n\n# Processing duration histogram\n{job=\"retroscope\"} |= \"METRIC:processing_speed\"\n| json\n| unwrap total_duration\n| histogram duration_seconds\n```\n\n### Token Usage\n```logql\n# Token usage by image type\nsum by (is_screenshot) (\n  {job=\"retroscope\"} |= \"METRIC:tokens_used\"\n  | json\n  | unwrap metric_value\n)\n\n# Average tokens per image over time\navg(rate({job=\"retroscope\"} |= \"METRIC:tokens_used\" | json | unwrap metric_value [5m]))\n```\n\n### Error Tracking\n```logql\n# Error rate\nsum(rate({job=\"retroscope\", level=\"error\"} [5m]))\n\n# Failed images count\n{job=\"retroscope\"} |= \"METRIC:total_cost\"\n| json\n| unwrap failed_images\n```\n\n### Success Rate\n```logql\n# Successful vs failed processing ratio\nsum by (success) (\n  {job=\"retroscope\"} |= \"METRIC:processing_cost\"\n  | json\n  | unwrap metric_value\n)\n```\n\nThese queries can be used to create dashboards showing:\n- Cost per image/batch\n- Processing speed and efficiency\n- Token usage patterns\n- Error rates and types\n- Success/failure ratios",
    "excerpt": "|   \\ | |              \n| |) /  \\ | '/  \\/ |/ /  \\| ' \\/ |\n|   <  / || | | () \\ \\ (| () | |) \\ \\\n|| \\\\|\\||  \\/|/\\\\/| ./|/..."
  },
  "createdAt": "2025-01-02T03:51:39Z",
  "updatedAt": "2025-08-06T16:15:39Z",
  "pushedAt": "2025-08-02T13:31:22Z"
}