{
  "name": "scrapbook-cli",
  "description": "A command line interface for exploring my scrapbook",
  "url": "https://github.com/ejfox/scrapbook-cli",
  "homepage": null,
  "stats": {
    "stars": 0,
    "forks": 0,
    "watchers": 1,
    "openIssues": 1
  },
  "language": "JavaScript",
  "languageColor": "#f1e05a",
  "languages": {
    "JavaScript": 190027
  },
  "diskUsage": 331,
  "fileTree": {
    "files": [
      {
        "path": ".gitignore",
        "size": 34
      },
      {
        "path": ".prettierignore",
        "size": 51
      },
      {
        "path": ".prettierrc",
        "size": 160
      },
      {
        "path": ".vscode/settings.json",
        "size": 268
      },
      {
        "path": "CHANGELOG.md",
        "size": 7855
      },
      {
        "path": "README.md",
        "size": 15857
      },
      {
        "path": "YOUTUBE-WORKFLOWS.md",
        "size": 14280
      },
      {
        "path": "analyze-entities.mjs",
        "size": 2149
      },
      {
        "path": "config-tool.js",
        "size": 9918
      },
      {
        "path": "config.js",
        "size": 1440
      },
      {
        "path": "config.yaml",
        "size": 4735
      },
      {
        "path": "config/loader.js",
        "size": 9954
      },
      {
        "path": "config/themes.yaml",
        "size": 8058
      },
      {
        "path": "config/validator.js",
        "size": 6273
      },
      {
        "path": "constants.js",
        "size": 1048
      },
      {
        "path": "database.js",
        "size": 33375
      },
      {
        "path": "docs/CLI-EXAMPLES.md",
        "size": 6168
      },
      {
        "path": "docs/CONFIG-ADVANCED.md",
        "size": 8347
      },
      {
        "path": "docs/CONFIG.md",
        "size": 3016
      },
      {
        "path": "docs/INTEGRATIONS.md",
        "size": 8109
      },
      {
        "path": "docs/THEMING.md",
        "size": 3776
      },
      {
        "path": "enrich-youtube-api.js",
        "size": 4753
      },
      {
        "path": "enrich-youtube.js",
        "size": 6146
      },
      {
        "path": "eslint.config.js",
        "size": 611
      },
      {
        "path": "examples/completions/_scrapbook-cli",
        "size": 2166
      },
      {
        "path": "examples/completions/scrapbook-cli.fish",
        "size": 2829
      },
      {
        "path": "examples/config.development.yaml.example",
        "size": 788
      },
      {
        "path": "examples/config.example.yaml",
        "size": 1808
      },
      {
        "path": "examples/config.production.yaml.example",
        "size": 932
      },
      {
        "path": "examples/sketchybar/scrapbook.sh",
        "size": 1270
      },
      {
        "path": "import-youtube-watchlater.js",
        "size": 4344
      },
      {
        "path": "index.mjs",
        "size": 23319
      },
      {
        "path": "package-lock.json",
        "size": 171649
      },
      {
        "path": "package.json",
        "size": 1584
      },
      {
        "path": "playlist.txt",
        "size": 644
      },
      {
        "path": "themes.js",
        "size": 2523
      },
      {
        "path": "themes/vulpes-reddishnovember-dark.toml",
        "size": 3219
      },
      {
        "path": "tui.js",
        "size": 27953
      },
      {
        "path": "ui/entity-graph.js",
        "size": 20147
      },
      {
        "path": "ui/force-layout.js",
        "size": 13248
      },
      {
        "path": "ui/map-view.js",
        "size": 3732
      },
      {
        "path": "ui/safe-exec.js",
        "size": 9239
      },
      {
        "path": "ui/state.js",
        "size": 1159
      },
      {
        "path": "yarn.lock",
        "size": 107535
      },
      {
        "path": "youtube.js",
        "size": 8696
      }
    ],
    "tree": {
      "name": "scrapbook-cli",
      "children": [
        {
          "name": ".vscode",
          "children": [
            {
              "name": "settings.json",
              "size": 268,
              "path": ".vscode/settings.json"
            }
          ],
          "path": ".vscode"
        },
        {
          "name": "config",
          "children": [
            {
              "name": "loader.js",
              "size": 9954,
              "path": "config/loader.js"
            },
            {
              "name": "themes.yaml",
              "size": 8058,
              "path": "config/themes.yaml"
            },
            {
              "name": "validator.js",
              "size": 6273,
              "path": "config/validator.js"
            }
          ],
          "path": "config"
        },
        {
          "name": "docs",
          "children": [
            {
              "name": "CLI-EXAMPLES.md",
              "size": 6168,
              "path": "docs/CLI-EXAMPLES.md"
            },
            {
              "name": "CONFIG-ADVANCED.md",
              "size": 8347,
              "path": "docs/CONFIG-ADVANCED.md"
            },
            {
              "name": "CONFIG.md",
              "size": 3016,
              "path": "docs/CONFIG.md"
            },
            {
              "name": "INTEGRATIONS.md",
              "size": 8109,
              "path": "docs/INTEGRATIONS.md"
            },
            {
              "name": "THEMING.md",
              "size": 3776,
              "path": "docs/THEMING.md"
            }
          ],
          "path": "docs"
        },
        {
          "name": "examples",
          "children": [
            {
              "name": "completions",
              "children": [
                {
                  "name": "_scrapbook-cli",
                  "size": 2166,
                  "path": "examples/completions/_scrapbook-cli"
                },
                {
                  "name": "scrapbook-cli.fish",
                  "size": 2829,
                  "path": "examples/completions/scrapbook-cli.fish"
                }
              ],
              "path": "examples/completions"
            },
            {
              "name": "sketchybar",
              "children": [
                {
                  "name": "scrapbook.sh",
                  "size": 1270,
                  "path": "examples/sketchybar/scrapbook.sh"
                }
              ],
              "path": "examples/sketchybar"
            },
            {
              "name": "config.development.yaml.example",
              "size": 788,
              "path": "examples/config.development.yaml.example"
            },
            {
              "name": "config.example.yaml",
              "size": 1808,
              "path": "examples/config.example.yaml"
            },
            {
              "name": "config.production.yaml.example",
              "size": 932,
              "path": "examples/config.production.yaml.example"
            }
          ],
          "path": "examples"
        },
        {
          "name": "themes",
          "children": [
            {
              "name": "vulpes-reddishnovember-dark.toml",
              "size": 3219,
              "path": "themes/vulpes-reddishnovember-dark.toml"
            }
          ],
          "path": "themes"
        },
        {
          "name": "ui",
          "children": [
            {
              "name": "entity-graph.js",
              "size": 20147,
              "path": "ui/entity-graph.js"
            },
            {
              "name": "force-layout.js",
              "size": 13248,
              "path": "ui/force-layout.js"
            },
            {
              "name": "map-view.js",
              "size": 3732,
              "path": "ui/map-view.js"
            },
            {
              "name": "safe-exec.js",
              "size": 9239,
              "path": "ui/safe-exec.js"
            },
            {
              "name": "state.js",
              "size": 1159,
              "path": "ui/state.js"
            }
          ],
          "path": "ui"
        },
        {
          "name": ".gitignore",
          "size": 34,
          "path": ".gitignore"
        },
        {
          "name": ".prettierignore",
          "size": 51,
          "path": ".prettierignore"
        },
        {
          "name": ".prettierrc",
          "size": 160,
          "path": ".prettierrc"
        },
        {
          "name": "CHANGELOG.md",
          "size": 7855,
          "path": "CHANGELOG.md"
        },
        {
          "name": "README.md",
          "size": 15857,
          "path": "README.md"
        },
        {
          "name": "YOUTUBE-WORKFLOWS.md",
          "size": 14280,
          "path": "YOUTUBE-WORKFLOWS.md"
        },
        {
          "name": "analyze-entities.mjs",
          "size": 2149,
          "path": "analyze-entities.mjs"
        },
        {
          "name": "config-tool.js",
          "size": 9918,
          "path": "config-tool.js"
        },
        {
          "name": "config.js",
          "size": 1440,
          "path": "config.js"
        },
        {
          "name": "config.yaml",
          "size": 4735,
          "path": "config.yaml"
        },
        {
          "name": "constants.js",
          "size": 1048,
          "path": "constants.js"
        },
        {
          "name": "database.js",
          "size": 33375,
          "path": "database.js"
        },
        {
          "name": "enrich-youtube-api.js",
          "size": 4753,
          "path": "enrich-youtube-api.js"
        },
        {
          "name": "enrich-youtube.js",
          "size": 6146,
          "path": "enrich-youtube.js"
        },
        {
          "name": "eslint.config.js",
          "size": 611,
          "path": "eslint.config.js"
        },
        {
          "name": "import-youtube-watchlater.js",
          "size": 4344,
          "path": "import-youtube-watchlater.js"
        },
        {
          "name": "index.mjs",
          "size": 23319,
          "path": "index.mjs"
        },
        {
          "name": "package-lock.json",
          "size": 171649,
          "path": "package-lock.json"
        },
        {
          "name": "package.json",
          "size": 1584,
          "path": "package.json"
        },
        {
          "name": "playlist.txt",
          "size": 644,
          "path": "playlist.txt"
        },
        {
          "name": "themes.js",
          "size": 2523,
          "path": "themes.js"
        },
        {
          "name": "tui.js",
          "size": 27953,
          "path": "tui.js"
        },
        {
          "name": "yarn.lock",
          "size": 107535,
          "path": "yarn.lock"
        },
        {
          "name": "youtube.js",
          "size": 8696,
          "path": "youtube.js"
        }
      ],
      "path": ""
    },
    "totalFiles": 45,
    "totalSize": 565165
  },
  "topics": [
    "cli"
  ],
  "readme": {
    "html": "<h1 id=\"scrapbook-cli\">Scrapbook CLI</h1>\n<p>A cyberpunk-inspired, terminal-based interface for your digital scrapbook. Dive into your memories, search through your digital artifacts, and relive your online adventures - all from the comfort of your command line.</p>\n<img width=\"1902\" alt=\"Screenshot 2024-07-07 at 10 32 56 PM\" src=\"https://github.com/ejfox/scrapbook-cli/assets/530073/4c505956-4fa1-460e-8544-3f81becdc3cb\" />\n<img width=\"1902\" alt=\"Screenshot 2024-07-07 at 10 32 44 PM\" src=\"https://github.com/ejfox/scrapbook-cli/assets/530073/11378745-d0dd-4987-9076-470180a1a1d3\" />\n<h2 id=\"features\">Features</h2>\n<h3 id=\"interactive-tui-mode\">Interactive TUI Mode</h3>\n<ul>\n<li>Browse your entire scrapbook collection</li>\n<li>Fuzzy search with fzf integration</li>\n<li>Slick, cyberpunk-themed UI</li>\n<li>Lightning-fast navigation</li>\n<li>Quick-copy links to clipboard</li>\n<li>Open entries directly in your browser</li>\n<li>Visual type indicators for different entry sources</li>\n<li>Mini-map view for entries with location data</li>\n<li>Full-screen map view of all geotagged entries</li>\n<li><strong>Interactive graph explorer</strong> - d3-force powered entity relationship visualization</li>\n</ul>\n<h3 id=\"cli-mode-unix-friendly\">CLI Mode (Unix-Friendly)</h3>\n<ul>\n<li>Multiple output formats: JSON, JSONL, TSV, CSV</li>\n<li>Field extraction for perfect piping</li>\n<li>AI-powered analysis with <code>llm</code> tool integration</li>\n<li>Composable with jq, fzf, grep, awk, curl</li>\n<li>Structured output for scripting and automation</li>\n<li>Search with reliable keyword matching</li>\n<li>Knowledge graph queries by entity with fuzzy matching</li>\n</ul>\n<h2 id=\"installation\">Installation</h2>\n<pre><code class=\"language-bash\">npm install -g scrapbook-cli\n</code></pre>\n<h2 id=\"usage\">Usage</h2>\n<h3 id=\"tui-mode-interactive\">TUI Mode (Interactive)</h3>\n<p>Launch the interactive TUI (default):</p>\n<pre><code class=\"language-bash\">scrapbook-cli\n# or explicitly\nscrapbook-cli ui\n</code></pre>\n<p>View the full-screen map of all geotagged entries:</p>\n<pre><code class=\"language-bash\">scrapbook-cli --map\n</code></pre>\n<h3 id=\"cli-mode-unix-friendly-1\">CLI Mode (Unix-Friendly)</h3>\n<p>scrapbook-cli is designed as a good Unix citizen, outputting structured data that pipes perfectly with tools like <code>jq</code>, <code>fzf</code>, <code>llm</code>, and standard commands.</p>\n<h4 id=\"default-human-readable-output\">Default Human-Readable Output</h4>\n<p>All list and search commands output beautiful, human-readable formatting by default:</p>\n<pre><code class=\"language-bash\"># Search (beautifully formatted by default)\nscrap search \"ai\"\n# Output:\n# 12/15 ‚óá OpenAI announces GPT-4 Turbo\n#     OpenAI has released GPT-4 Turbo, a powerful new model with improved...\n#     https://openai.com/blog/gpt-4-turbo/\n#\n# 12/14 ‚ñ£ Deep Learning Fundamentals\n#     A comprehensive guide to deep learning principles and implementation...\n#     https://deeplearning.example.com\n#\n# 2 results found\n\n# List with human-readable format (default)\nscrap list --limit 5\n</code></pre>\n<h4 id=\"output-formats\">Output Formats</h4>\n<p>All commands support multiple output formats for piping:</p>\n<pre><code class=\"language-bash\"># Human-readable (default - no flag needed)\nscrap search \"kubernetes\"\n\n# JSON (pretty-printed)\nscrap list --json\n\n# JSON Lines (one per line, great for streaming)\nscrap search \"ai\" --jsonl\n\n# TSV (tab-separated, easy to parse with cut/awk)\nscrap list --tsv\n\n# CSV (for spreadsheet analysis)\nscrap list --csv\n\n# fzf-compatible format (indexed, ready to pipe to fzf)\nscrap search \"python\" --fzf | fzf --preview 'scrap get {1}'\n\n# With result limiting\nscrap list --json --limit 10\n</code></pre>\n<h4 id=\"list-bookmarks\">List bookmarks</h4>\n<pre><code class=\"language-bash\"># Human-readable format (default)\nscrap list\n\n# Pretty JSON\nscrap list --json\n\n# One per line (for processing)\nscrap list --jsonl\n\n# Tab-separated (for parsing)\nscrap list --tsv\n\n# CSV for Excel/spreadsheet\nscrap list --csv\n\n# Limit to 10 most recent\nscrap list --limit 10\n\n# Combine formats and limits\nscrap search \"machine learning\" --json --limit 5\n</code></pre>\n<h4 id=\"search-bookmarks\">Search bookmarks</h4>\n<pre><code class=\"language-bash\"># Human-readable search (default)\nscrap search \"election\"\n\n# Search with specific output formats\nscrap search \"kubernetes\" --json\nscrap search \"ai\" --tsv\nscrap search \"python\" --csv\nscrap search \"golang\" --jsonl\n</code></pre>\n<h4 id=\"get-specific-bookmark\">Get specific bookmark</h4>\n<pre><code class=\"language-bash\"># Get full bookmark as JSON\nscrap get &lt;scrap_id&gt;\n\n# Extract specific field (perfect for piping)\nscrap get &lt;scrap_id&gt; --field url\nscrap get &lt;scrap_id&gt; --field title\nscrap get &lt;scrap_id&gt; --field tags\nscrap get &lt;scrap_id&gt; --field summary\n</code></pre>\n<h4 id=\"query-knowledge-graph-by-entity\">Query knowledge graph by entity</h4>\n<pre><code class=\"language-bash\"># Find all scraps mentioning an entity (with fuzzy matching)\nscrap entity \"Senator James Skoufis\"\n\n# Output connections as JSON\nscrap entity \"New York Attorney General\" --connections\n\n# Output graph structure\nscrap entity \"Skoufis\" --graph\n\n# Full data output\nscrap entity \"Skoufis\" --json\n</code></pre>\n<h4 id=\"interactive-graph-explorer-hacker-mode\">Interactive graph explorer (Hacker Mode)</h4>\n<pre><code class=\"language-bash\"># Launch d3-force powered TUI to explore entity relationships\nscrapbook-cli graph \"Skoufis\"\n\n# Controls:\n# ‚Üë‚Üì/j/k    Navigate nodes\n# ENTER     Explore selected entity (recursive dive)\n# E         Expand network from selected node\n# L         List all scraps for selected entity\n# +         Expand all connected nodes (depth++)\n# SPACE     Toggle physics animation\n# R         Reset simulation\n# Q         Quit\n\n# Status bar shows:\n# - Network size (nodes/links)\n# - Current depth\n# - Expanded entities count (marked with ‚óè in connections list)\n# - Animation status (‚ñ∂ Running / ‚è∏ Paused)\n\n# Hacker workflow:\nscrapbook-cli graph \"Skoufis\"\n# Navigate to \"New York Attorney General\"\n# Press E to expand that entity's network\n# Watch new nodes and links appear dynamically\n# Press + to expand ALL connected nodes (spider out)\n# Press L to see which scraps mention the entity\n</code></pre>\n<h4 id=\"financial-analysis-and-sentiment-tracking\">Financial analysis and sentiment tracking</h4>\n<p>Query financial assets mentioned in your scraps with automatic ticker extraction and sentiment analysis:</p>\n<pre><code class=\"language-bash\"># View all discovered financial assets and their sentiment\nscrap financial\n\n# Filter by ticker symbol\nscrap financial --ticker PLTR\n\n# Filter by sentiment range (-1 to 1, where -1 is very negative, 1 is very positive)\nscrap financial --sentiment-min 0.5  # Only positive assets\nscrap financial --sentiment-max -0.3 # Only negative assets\n\n# Show only tracked assets (vs discovered)\nscrap financial --tracked\n\n# Output as JSON for piping\nscrap financial --json\nscrap financial --jsonl\nscrap financial --csv\nscrap financial --tsv\n</code></pre>\n<p>Example output:</p>\n<pre><code>üí∞ Financial Assets (49 unique)\n\nPLTR     Palantir Technologies Inc.\n  Mentions: 7 | Sentiment: üìâ -0.06 (-0.80~0.80)\n  Type: stock\n  Latest: The most dangerous man in America isn't Trump‚Äîit's Alex Karp\n\nOPENAI   OpenAI\n  Mentions: 3 | Sentiment: üìà +0.47 (0.40~0.50)\n  Type: private_company\n  Latest: Five news orgs join Lenfest AI Collaborative...\n\nMNMD     MindMed Inc.\n  Mentions: 1 | Sentiment: üìà +0.70 (0.70~0.70)\n  Type: stock\n  Latest: A Startup Used AI to Make a Psychedelic Without the Trip...\n</code></pre>\n<p>Each asset shows:</p>\n<ul>\n<li><strong>Ticker</strong>: Stock symbol or unique identifier</li>\n<li><strong>Name</strong>: Company or asset name</li>\n<li><strong>Mentions</strong>: How many times mentioned across your scraps</li>\n<li><strong>Sentiment</strong>: Average sentiment with range (min~max)</li>\n<li><strong>Type</strong>: Asset type (stock, private_company, forex, crypto, etc.)</li>\n<li><strong>Latest</strong>: Most recent article mentioning this asset</li>\n</ul>\n<h3 id=\"cli-piping-recipes\">CLI Piping Recipes</h3>\n<p>scrapbook-cli is designed to compose beautifully with Unix tools. Use <code>--json</code>, <code>--jsonl</code>, <code>--tsv</code>, <code>--csv</code>, or <code>--fzf</code> to integrate with your workflow.</p>\n<h4 id=\"jq-recipes-json-parsing\">jq Recipes (JSON Parsing)</h4>\n<pre><code class=\"language-bash\"># Get all titles\nscrap list --json | jq -r '.[].title'\n\n# Get URLs only\nscrap list --json | jq -r '.[].url'\n\n# Get bookmarks from pinboard source\nscrap list --json | jq '.[] | select(.source == \"pinboard\") | .url'\n\n# Count bookmarks by source\nscrap list --json | jq 'group_by(.source) | map({source: .[0].source, count: length})'\n\n# Extract all tags (unique)\nscrap list --json | jq -r '.[].tags[]' | sort | uniq\n\n# Build a markdown reading list\nscrap search \"article\" --json | jq -r '.[] | \"- [\\(.title)](\\(.url))\"'\n\n# Get entries with relationships\nscrap list --json | jq '.[] | select(.relationships | length &gt; 0) | {title, relationship_count: (.relationships | length)}'\n\n# Find most common tags\nscrap list --json | jq -r '.[].tags[]' | sort | uniq -c | sort -rn | head -10\n\n# Get random bookmark\nscrap list --json | jq -r '.[].url' | shuf -n 1\n</code></pre>\n<h4 id=\"fzf-integration-interactive-selection\">fzf Integration (Interactive Selection)</h4>\n<pre><code class=\"language-bash\"># Interactive search with preview\nscrap search \"python\" --fzf | fzf --preview 'echo {} | cut -f2-'\n\n# Select and open in browser\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {} --field url | xargs open\n\n# Select and copy URL to clipboard\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {} --field url | pbcopy\n\n# Select entry and view full details\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {}\n\n# Fuzzy find with live preview of URLs\nscrap list --fzf | fzf --preview 'echo {} | cut -f1 | xargs -I ID scrap get ID --field url'\n\n# Multi-select bookmarks for bulk export\nscrap search \"research\" --fzf | fzf -m | awk '{print $1}' | xargs -I {} scrap get {} --json &gt; research-batch.json\n</code></pre>\n<h4 id=\"csv-export\">CSV Export</h4>\n<pre><code class=\"language-bash\"># Export to CSV for spreadsheet analysis\nscrap list --csv &gt; bookmarks.csv\n\n# Export search results to CSV\nscrap search \"python\" --csv &gt; python-bookmarks.csv\n</code></pre>\n<h4 id=\"search--entity-operations\">Search &amp; Entity Operations</h4>\n<pre><code class=\"language-bash\"># Find all mentions of entity, extract titles\nscrap entity \"OpenAI\" --json | jq -r '.scraps[].title'\n\n# Get all scraps for an entity as JSON\nscrap entity \"Claude\" --json | jq '.scraps' &gt; claude-mentions.json\n\n# Get entity connection count\nscrap entity \"Tesla\" --json | jq '.total_scraps'\n</code></pre>\n<h4 id=\"bulk-operations--backup\">Bulk Operations &amp; Backup</h4>\n<pre><code class=\"language-bash\"># Export entire library as JSON\nscrap list --json &gt; my-scrapbook.json\n\n# Backup to JSONL (one record per line, better for version control)\nscrap list --jsonl &gt; scrapbook-backup.jsonl\n\n# Create a dated backup\nscrap list --json &gt; \"scrapbook-$(date +%Y-%m-%d).json\"\n\n# Count total bookmarks\nscrap list --json | jq 'length'\n\n# Get stats: count by source\nscrap list --json | jq 'group_by(.source) | map({source: .[0].source, count: length})'\n\n# Export URLs only (one per line)\nscrap list --json | jq -r '.[].url' &gt; all-urls.txt\n\n# Export titles only\nscrap list --json | jq -r '.[].title' &gt; all-titles.txt\n</code></pre>\n<h4 id=\"llm-ready-output-pipe-to-external-tools\">LLM-Ready Output (Pipe to External Tools)</h4>\n<p>scrapbook-cli outputs are optimized for piping to external LLM CLI tools like <code>llm</code>, <code>gpt-cli</code>, etc.</p>\n<pre><code class=\"language-bash\"># Pipe summaries to llm for analysis\nscrap list --json --limit 10 | jq -r '.[].summary' | llm -m gpt-4o-mini \"Summarize these into 3-5 topics\"\n\n# Analyze search results\nscrap search \"climate\" --json | jq -r '.[] | \"\\(.title): \\(.summary)\"' | llm \"Extract main policy proposals\"\n\n# Generate tags from titles\nscrap list --json | jq -r '.[] | select(.tags | length == 0) | .title' | llm \"Suggest 3 tags for each\"\n\n# Extract themes from content\nscrap search \"technology\" --json | jq -r '.[].content' | llm \"List the main technical themes\"\n\n# Analyze entity relationships\nscrap entity \"OpenAI\" --json | jq -r '.scraps[].title' | llm \"What are the main topics?\"\n\n# Create reading list with AI summaries\nscrap search \"research\" --json | jq -r '.[] | .title' | llm \"Rank these by importance\"\n\n# Compare bookmarks\n(scrap get &lt;id1&gt; --field summary &amp;&amp; echo \"---\" &amp;&amp; scrap get &lt;id2&gt; --field summary) | llm \"Compare these concepts\"\n</code></pre>\n<h4 id=\"financial-analysis-recipes\">Financial Analysis Recipes</h4>\n<pre><code class=\"language-bash\"># Get all tickers with their sentiment scores\nscrap financial --json | jq -r '.[] | \"\\(.ticker): \\(.avg_sentiment | tostring)\"'\n\n# Find assets with very negative sentiment (below -0.5)\nscrap financial --json | jq '.[] | select(.avg_sentiment &lt; -0.5) | {ticker, name, sentiment: .avg_sentiment}'\n\n# Count assets by type\nscrap financial --json | jq 'group_by(.asset_type) | map({type: .[0].asset_type, count: length})'\n\n# Get most mentioned assets\nscrap financial --json | jq 'sort_by(.mention_count) | reverse | .[0:10] | .[] | {ticker, name, mentions: .mention_count}'\n\n# Find assets mentioned only once (emerging/niche topics)\nscrap financial --json | jq '.[] | select(.mention_count == 1) | {ticker, name}'\n\n# Export sentiment timeline for a ticker\nscrap financial --json | jq '.[] | select(.ticker == \"PLTR\") | .scraps[] | {date: .created_at, sentiment: .sentiment_score, title}'\n\n# Compare sentiment across multiple assets\nscrap financial --json | jq '[.[] | select(.ticker == \"PLTR\" or .ticker == \"OPENAI\") | {ticker, avg_sentiment}]'\n\n# Find articles mentioning an asset with the most negative context\nscrap financial --ticker PLTR --json | jq '.[] | .scraps | min_by(.sentiment_score) | {title, url, sentiment: .sentiment_score}'\n\n# Analyze asset concentration (how diversified your financial discussion is)\nscrap financial --json | jq '{total_mentions: map(.mention_count) | add, unique_assets: length, concentration: (map(.mention_count) | max)}'\n\n# Export as CSV for spreadsheet analysis\nscrap financial --csv &gt; financial-sentiment-analysis.csv\n</code></pre>\n<h4 id=\"setup-alias--dev-mode\">Setup (Alias &amp; Dev Mode)</h4>\n<p>If you're developing scrapbook-cli, you can set up a dev alias:</p>\n<pre><code class=\"language-bash\"># Link to your local development version\ncd /path/to/scrapbook-cli\nnpm link\n\n# Create a short alias in ~/.zshrc or ~/.bashrc\nalias scrap=\"scrapbook-cli\"\n\n# Now all changes to the code are immediately available\nscrap search \"test\"  # Uses your local dev version\n</code></pre>\n<h3 id=\"youtube-playlist--transcription-workflows\">YouTube Playlist &amp; Transcription Workflows</h3>\n<p>Create yt-dlp playlists and Whisper transcriptions for video essay research:</p>\n<pre><code class=\"language-bash\"># Generate playlist filtered by entity\nscrapbook-cli youtube generate --entity \"Palantir\" -o palantir.txt\n\n# Download and transcribe automatically\nscrapbook-cli youtube transcribe \\\n  --entity \"Peter Thiel\" \\\n  --output-dir ./transcripts \\\n  --model base\n\n# Filter by tags for themed playlists\nscrapbook-cli youtube generate \\\n  --tag AI --tag machinelearning \\\n  -o ai-videos.txt\n\n# Download with yt-dlp\nyt-dlp -a ai-videos.txt --write-auto-sub --sub-lang en\n\n# Analyze transcripts with llm\ncat transcripts/*.txt | llm \"Summarize the main themes\"\n\n# View collection stats\nscrapbook-cli youtube stats\n</code></pre>\n<p>See <a href=\"./YOUTUBE-WORKFLOWS.md\">YOUTUBE-WORKFLOWS.md</a> for complete video essay research workflows.</p>\n<h2 id=\"power-user-integrations\">Power User Integrations</h2>\n<p>scrapbook-cli integrates seamlessly with your power user workflow:</p>\n<ul>\n<li><strong>fzf</strong>: Standalone fuzzy finder mode (<code>scrapbook-cli fzf</code>)</li>\n<li><strong>Zsh/Fish completions</strong>: Tab completion for all commands</li>\n<li><strong>Powerlevel10k</strong>: Show bookmark count in your prompt</li>\n<li><strong>SketchyBar</strong>: Display bookmark stats in your macOS menu bar</li>\n<li><strong>Shell keybindings</strong>: Quick access with Ctrl+B</li>\n<li><strong>Alfred/Raycast</strong>: Search workflows</li>\n</ul>\n<p>See <a href=\"./docs/INTEGRATIONS.md\">INTEGRATIONS.md</a> for detailed setup instructions.</p>\n<h3 id=\"controls-list-mode\">Controls (List Mode)</h3>\n<ul>\n<li><code>‚Üë/‚Üì</code> or <code>j/k</code>: Navigate entries</li>\n<li><code>‚Üí</code>: Copy public URL to clipboard</li>\n<li><code>‚Üê</code>: Copy entry URL to clipboard</li>\n<li><code>Space</code>: Open entry in browser</li>\n<li><code>e</code>: Open entry in $EDITOR (nvim/vim/etc)</li>\n<li><code>z</code>: Toggle full-screen summary view</li>\n<li><code>/</code> or <code>s</code>: Search entries</li>\n<li><code>r</code>: Refresh entries</li>\n<li><code>PageUp/PageDown</code>: Move 24 entries at a time</li>\n<li><code>Esc</code>: Exit search or full-screen view</li>\n<li><code>q</code>: Quit</li>\n</ul>\n<h3 id=\"controls-map-mode\">Controls (Map Mode)</h3>\n<ul>\n<li><code>‚Üë/‚Üì</code>: Navigate through map markers</li>\n<li><code>q</code>: Quit</li>\n</ul>\n<h2 id=\"mini-map-feature\">Mini-Map Feature</h2>\n<p>The mini-map displays the location of the currently selected entry if it has latitude and longitude data. If an entry doesn't have location data, the mini-map will be hidden.</p>\n<h2 id=\"full-screen-map-view\">Full-Screen Map View</h2>\n<p>The full-screen map view shows all your geotagged entries on a world map. Navigate through the markers to see details about each entry.</p>\n<h2 id=\"json-export\">JSON Export</h2>\n<p>Use the <code>json</code> command followed by a scrap ID to get the full JSON data for that specific scrap. This is useful for debugging or data export purposes.</p>\n<h2 id=\"configuration\">Configuration</h2>\n<p>Scrapbook CLI uses environment variables for configuration. Create a <code>.env</code> file in your home directory with the following:</p>\n<pre><code>SUPABASE_URL=your_supabase_url\nSUPABASE_KEY=your_supabase_key\n</code></pre>\n<h2 id=\"contributing\">Contributing</h2>\n<p>Pull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.</p>\n<h2 id=\"license\">License</h2>\n<p><a href=\"https://choosealicense.com/licenses/mit/\">MIT</a></p>\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n<p>Built with love, caffeine, and a dash of cyberpunk nostalgia. Special thanks to the creators of blessed, blessed-contrib, and Supabase for making this CLI possible.</p>",
    "raw": "# Scrapbook CLI\n\nA cyberpunk-inspired, terminal-based interface for your digital scrapbook. Dive into your memories, search through your digital artifacts, and relive your online adventures - all from the comfort of your command line.\n\n<img width=\"1902\" alt=\"Screenshot 2024-07-07 at 10 32 56 PM\" src=\"https://github.com/ejfox/scrapbook-cli/assets/530073/4c505956-4fa1-460e-8544-3f81becdc3cb\">\n\n<img width=\"1902\" alt=\"Screenshot 2024-07-07 at 10 32 44 PM\" src=\"https://github.com/ejfox/scrapbook-cli/assets/530073/11378745-d0dd-4987-9076-470180a1a1d3\">\n\n## Features\n\n### Interactive TUI Mode\n- Browse your entire scrapbook collection\n- Fuzzy search with fzf integration\n- Slick, cyberpunk-themed UI\n- Lightning-fast navigation\n- Quick-copy links to clipboard\n- Open entries directly in your browser\n- Visual type indicators for different entry sources\n- Mini-map view for entries with location data\n- Full-screen map view of all geotagged entries\n- **Interactive graph explorer** - d3-force powered entity relationship visualization\n\n### CLI Mode (Unix-Friendly)\n- Multiple output formats: JSON, JSONL, TSV, CSV\n- Field extraction for perfect piping\n- AI-powered analysis with `llm` tool integration\n- Composable with jq, fzf, grep, awk, curl\n- Structured output for scripting and automation\n- Search with reliable keyword matching\n- Knowledge graph queries by entity with fuzzy matching\n\n## Installation\n\n```bash\nnpm install -g scrapbook-cli\n```\n\n## Usage\n\n### TUI Mode (Interactive)\n\nLaunch the interactive TUI (default):\n\n```bash\nscrapbook-cli\n# or explicitly\nscrapbook-cli ui\n```\n\nView the full-screen map of all geotagged entries:\n\n```bash\nscrapbook-cli --map\n```\n\n### CLI Mode (Unix-Friendly)\n\nscrapbook-cli is designed as a good Unix citizen, outputting structured data that pipes perfectly with tools like `jq`, `fzf`, `llm`, and standard commands.\n\n#### Default Human-Readable Output\n\nAll list and search commands output beautiful, human-readable formatting by default:\n\n```bash\n# Search (beautifully formatted by default)\nscrap search \"ai\"\n# Output:\n# 12/15 ‚óá OpenAI announces GPT-4 Turbo\n#     OpenAI has released GPT-4 Turbo, a powerful new model with improved...\n#     https://openai.com/blog/gpt-4-turbo/\n#\n# 12/14 ‚ñ£ Deep Learning Fundamentals\n#     A comprehensive guide to deep learning principles and implementation...\n#     https://deeplearning.example.com\n#\n# 2 results found\n\n# List with human-readable format (default)\nscrap list --limit 5\n```\n\n#### Output Formats\n\nAll commands support multiple output formats for piping:\n\n```bash\n# Human-readable (default - no flag needed)\nscrap search \"kubernetes\"\n\n# JSON (pretty-printed)\nscrap list --json\n\n# JSON Lines (one per line, great for streaming)\nscrap search \"ai\" --jsonl\n\n# TSV (tab-separated, easy to parse with cut/awk)\nscrap list --tsv\n\n# CSV (for spreadsheet analysis)\nscrap list --csv\n\n# fzf-compatible format (indexed, ready to pipe to fzf)\nscrap search \"python\" --fzf | fzf --preview 'scrap get {1}'\n\n# With result limiting\nscrap list --json --limit 10\n```\n\n#### List bookmarks\n\n```bash\n# Human-readable format (default)\nscrap list\n\n# Pretty JSON\nscrap list --json\n\n# One per line (for processing)\nscrap list --jsonl\n\n# Tab-separated (for parsing)\nscrap list --tsv\n\n# CSV for Excel/spreadsheet\nscrap list --csv\n\n# Limit to 10 most recent\nscrap list --limit 10\n\n# Combine formats and limits\nscrap search \"machine learning\" --json --limit 5\n```\n\n#### Search bookmarks\n\n```bash\n# Human-readable search (default)\nscrap search \"election\"\n\n# Search with specific output formats\nscrap search \"kubernetes\" --json\nscrap search \"ai\" --tsv\nscrap search \"python\" --csv\nscrap search \"golang\" --jsonl\n```\n\n#### Get specific bookmark\n\n```bash\n# Get full bookmark as JSON\nscrap get <scrap_id>\n\n# Extract specific field (perfect for piping)\nscrap get <scrap_id> --field url\nscrap get <scrap_id> --field title\nscrap get <scrap_id> --field tags\nscrap get <scrap_id> --field summary\n```\n\n#### Query knowledge graph by entity\n\n```bash\n# Find all scraps mentioning an entity (with fuzzy matching)\nscrap entity \"Senator James Skoufis\"\n\n# Output connections as JSON\nscrap entity \"New York Attorney General\" --connections\n\n# Output graph structure\nscrap entity \"Skoufis\" --graph\n\n# Full data output\nscrap entity \"Skoufis\" --json\n```\n\n#### Interactive graph explorer (Hacker Mode)\n\n```bash\n# Launch d3-force powered TUI to explore entity relationships\nscrapbook-cli graph \"Skoufis\"\n\n# Controls:\n# ‚Üë‚Üì/j/k    Navigate nodes\n# ENTER     Explore selected entity (recursive dive)\n# E         Expand network from selected node\n# L         List all scraps for selected entity\n# +         Expand all connected nodes (depth++)\n# SPACE     Toggle physics animation\n# R         Reset simulation\n# Q         Quit\n\n# Status bar shows:\n# - Network size (nodes/links)\n# - Current depth\n# - Expanded entities count (marked with ‚óè in connections list)\n# - Animation status (‚ñ∂ Running / ‚è∏ Paused)\n\n# Hacker workflow:\nscrapbook-cli graph \"Skoufis\"\n# Navigate to \"New York Attorney General\"\n# Press E to expand that entity's network\n# Watch new nodes and links appear dynamically\n# Press + to expand ALL connected nodes (spider out)\n# Press L to see which scraps mention the entity\n```\n\n#### Financial analysis and sentiment tracking\n\nQuery financial assets mentioned in your scraps with automatic ticker extraction and sentiment analysis:\n\n```bash\n# View all discovered financial assets and their sentiment\nscrap financial\n\n# Filter by ticker symbol\nscrap financial --ticker PLTR\n\n# Filter by sentiment range (-1 to 1, where -1 is very negative, 1 is very positive)\nscrap financial --sentiment-min 0.5  # Only positive assets\nscrap financial --sentiment-max -0.3 # Only negative assets\n\n# Show only tracked assets (vs discovered)\nscrap financial --tracked\n\n# Output as JSON for piping\nscrap financial --json\nscrap financial --jsonl\nscrap financial --csv\nscrap financial --tsv\n```\n\nExample output:\n```\nüí∞ Financial Assets (49 unique)\n\nPLTR     Palantir Technologies Inc.\n  Mentions: 7 | Sentiment: üìâ -0.06 (-0.80~0.80)\n  Type: stock\n  Latest: The most dangerous man in America isn't Trump‚Äîit's Alex Karp\n\nOPENAI   OpenAI\n  Mentions: 3 | Sentiment: üìà +0.47 (0.40~0.50)\n  Type: private_company\n  Latest: Five news orgs join Lenfest AI Collaborative...\n\nMNMD     MindMed Inc.\n  Mentions: 1 | Sentiment: üìà +0.70 (0.70~0.70)\n  Type: stock\n  Latest: A Startup Used AI to Make a Psychedelic Without the Trip...\n```\n\nEach asset shows:\n- **Ticker**: Stock symbol or unique identifier\n- **Name**: Company or asset name\n- **Mentions**: How many times mentioned across your scraps\n- **Sentiment**: Average sentiment with range (min~max)\n- **Type**: Asset type (stock, private_company, forex, crypto, etc.)\n- **Latest**: Most recent article mentioning this asset\n\n### CLI Piping Recipes\n\nscrapbook-cli is designed to compose beautifully with Unix tools. Use `--json`, `--jsonl`, `--tsv`, `--csv`, or `--fzf` to integrate with your workflow.\n\n#### jq Recipes (JSON Parsing)\n\n```bash\n# Get all titles\nscrap list --json | jq -r '.[].title'\n\n# Get URLs only\nscrap list --json | jq -r '.[].url'\n\n# Get bookmarks from pinboard source\nscrap list --json | jq '.[] | select(.source == \"pinboard\") | .url'\n\n# Count bookmarks by source\nscrap list --json | jq 'group_by(.source) | map({source: .[0].source, count: length})'\n\n# Extract all tags (unique)\nscrap list --json | jq -r '.[].tags[]' | sort | uniq\n\n# Build a markdown reading list\nscrap search \"article\" --json | jq -r '.[] | \"- [\\(.title)](\\(.url))\"'\n\n# Get entries with relationships\nscrap list --json | jq '.[] | select(.relationships | length > 0) | {title, relationship_count: (.relationships | length)}'\n\n# Find most common tags\nscrap list --json | jq -r '.[].tags[]' | sort | uniq -c | sort -rn | head -10\n\n# Get random bookmark\nscrap list --json | jq -r '.[].url' | shuf -n 1\n```\n\n#### fzf Integration (Interactive Selection)\n\n```bash\n# Interactive search with preview\nscrap search \"python\" --fzf | fzf --preview 'echo {} | cut -f2-'\n\n# Select and open in browser\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {} --field url | xargs open\n\n# Select and copy URL to clipboard\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {} --field url | pbcopy\n\n# Select entry and view full details\nscrap list --fzf | fzf | awk '{print $1}' | xargs -I {} scrap get {}\n\n# Fuzzy find with live preview of URLs\nscrap list --fzf | fzf --preview 'echo {} | cut -f1 | xargs -I ID scrap get ID --field url'\n\n# Multi-select bookmarks for bulk export\nscrap search \"research\" --fzf | fzf -m | awk '{print $1}' | xargs -I {} scrap get {} --json > research-batch.json\n```\n\n#### CSV Export\n\n```bash\n# Export to CSV for spreadsheet analysis\nscrap list --csv > bookmarks.csv\n\n# Export search results to CSV\nscrap search \"python\" --csv > python-bookmarks.csv\n```\n\n#### Search & Entity Operations\n\n```bash\n# Find all mentions of entity, extract titles\nscrap entity \"OpenAI\" --json | jq -r '.scraps[].title'\n\n# Get all scraps for an entity as JSON\nscrap entity \"Claude\" --json | jq '.scraps' > claude-mentions.json\n\n# Get entity connection count\nscrap entity \"Tesla\" --json | jq '.total_scraps'\n```\n\n#### Bulk Operations & Backup\n\n```bash\n# Export entire library as JSON\nscrap list --json > my-scrapbook.json\n\n# Backup to JSONL (one record per line, better for version control)\nscrap list --jsonl > scrapbook-backup.jsonl\n\n# Create a dated backup\nscrap list --json > \"scrapbook-$(date +%Y-%m-%d).json\"\n\n# Count total bookmarks\nscrap list --json | jq 'length'\n\n# Get stats: count by source\nscrap list --json | jq 'group_by(.source) | map({source: .[0].source, count: length})'\n\n# Export URLs only (one per line)\nscrap list --json | jq -r '.[].url' > all-urls.txt\n\n# Export titles only\nscrap list --json | jq -r '.[].title' > all-titles.txt\n```\n\n#### LLM-Ready Output (Pipe to External Tools)\n\nscrapbook-cli outputs are optimized for piping to external LLM CLI tools like `llm`, `gpt-cli`, etc.\n\n```bash\n# Pipe summaries to llm for analysis\nscrap list --json --limit 10 | jq -r '.[].summary' | llm -m gpt-4o-mini \"Summarize these into 3-5 topics\"\n\n# Analyze search results\nscrap search \"climate\" --json | jq -r '.[] | \"\\(.title): \\(.summary)\"' | llm \"Extract main policy proposals\"\n\n# Generate tags from titles\nscrap list --json | jq -r '.[] | select(.tags | length == 0) | .title' | llm \"Suggest 3 tags for each\"\n\n# Extract themes from content\nscrap search \"technology\" --json | jq -r '.[].content' | llm \"List the main technical themes\"\n\n# Analyze entity relationships\nscrap entity \"OpenAI\" --json | jq -r '.scraps[].title' | llm \"What are the main topics?\"\n\n# Create reading list with AI summaries\nscrap search \"research\" --json | jq -r '.[] | .title' | llm \"Rank these by importance\"\n\n# Compare bookmarks\n(scrap get <id1> --field summary && echo \"---\" && scrap get <id2> --field summary) | llm \"Compare these concepts\"\n```\n\n#### Financial Analysis Recipes\n\n```bash\n# Get all tickers with their sentiment scores\nscrap financial --json | jq -r '.[] | \"\\(.ticker): \\(.avg_sentiment | tostring)\"'\n\n# Find assets with very negative sentiment (below -0.5)\nscrap financial --json | jq '.[] | select(.avg_sentiment < -0.5) | {ticker, name, sentiment: .avg_sentiment}'\n\n# Count assets by type\nscrap financial --json | jq 'group_by(.asset_type) | map({type: .[0].asset_type, count: length})'\n\n# Get most mentioned assets\nscrap financial --json | jq 'sort_by(.mention_count) | reverse | .[0:10] | .[] | {ticker, name, mentions: .mention_count}'\n\n# Find assets mentioned only once (emerging/niche topics)\nscrap financial --json | jq '.[] | select(.mention_count == 1) | {ticker, name}'\n\n# Export sentiment timeline for a ticker\nscrap financial --json | jq '.[] | select(.ticker == \"PLTR\") | .scraps[] | {date: .created_at, sentiment: .sentiment_score, title}'\n\n# Compare sentiment across multiple assets\nscrap financial --json | jq '[.[] | select(.ticker == \"PLTR\" or .ticker == \"OPENAI\") | {ticker, avg_sentiment}]'\n\n# Find articles mentioning an asset with the most negative context\nscrap financial --ticker PLTR --json | jq '.[] | .scraps | min_by(.sentiment_score) | {title, url, sentiment: .sentiment_score}'\n\n# Analyze asset concentration (how diversified your financial discussion is)\nscrap financial --json | jq '{total_mentions: map(.mention_count) | add, unique_assets: length, concentration: (map(.mention_count) | max)}'\n\n# Export as CSV for spreadsheet analysis\nscrap financial --csv > financial-sentiment-analysis.csv\n```\n\n#### Setup (Alias & Dev Mode)\n\nIf you're developing scrapbook-cli, you can set up a dev alias:\n\n```bash\n# Link to your local development version\ncd /path/to/scrapbook-cli\nnpm link\n\n# Create a short alias in ~/.zshrc or ~/.bashrc\nalias scrap=\"scrapbook-cli\"\n\n# Now all changes to the code are immediately available\nscrap search \"test\"  # Uses your local dev version\n```\n\n### YouTube Playlist & Transcription Workflows\n\nCreate yt-dlp playlists and Whisper transcriptions for video essay research:\n\n```bash\n# Generate playlist filtered by entity\nscrapbook-cli youtube generate --entity \"Palantir\" -o palantir.txt\n\n# Download and transcribe automatically\nscrapbook-cli youtube transcribe \\\n  --entity \"Peter Thiel\" \\\n  --output-dir ./transcripts \\\n  --model base\n\n# Filter by tags for themed playlists\nscrapbook-cli youtube generate \\\n  --tag AI --tag machinelearning \\\n  -o ai-videos.txt\n\n# Download with yt-dlp\nyt-dlp -a ai-videos.txt --write-auto-sub --sub-lang en\n\n# Analyze transcripts with llm\ncat transcripts/*.txt | llm \"Summarize the main themes\"\n\n# View collection stats\nscrapbook-cli youtube stats\n```\n\nSee [YOUTUBE-WORKFLOWS.md](./YOUTUBE-WORKFLOWS.md) for complete video essay research workflows.\n\n## Power User Integrations\n\nscrapbook-cli integrates seamlessly with your power user workflow:\n\n- **fzf**: Standalone fuzzy finder mode (`scrapbook-cli fzf`)\n- **Zsh/Fish completions**: Tab completion for all commands\n- **Powerlevel10k**: Show bookmark count in your prompt\n- **SketchyBar**: Display bookmark stats in your macOS menu bar\n- **Shell keybindings**: Quick access with Ctrl+B\n- **Alfred/Raycast**: Search workflows\n\nSee [INTEGRATIONS.md](./docs/INTEGRATIONS.md) for detailed setup instructions.\n\n### Controls (List Mode)\n\n- `‚Üë/‚Üì` or `j/k`: Navigate entries\n- `‚Üí`: Copy public URL to clipboard\n- `‚Üê`: Copy entry URL to clipboard\n- `Space`: Open entry in browser\n- `e`: Open entry in $EDITOR (nvim/vim/etc)\n- `z`: Toggle full-screen summary view\n- `/` or `s`: Search entries\n- `r`: Refresh entries\n- `PageUp/PageDown`: Move 24 entries at a time\n- `Esc`: Exit search or full-screen view\n- `q`: Quit\n\n### Controls (Map Mode)\n\n- `‚Üë/‚Üì`: Navigate through map markers\n- `q`: Quit\n\n## Mini-Map Feature\n\nThe mini-map displays the location of the currently selected entry if it has latitude and longitude data. If an entry doesn't have location data, the mini-map will be hidden.\n\n## Full-Screen Map View\n\nThe full-screen map view shows all your geotagged entries on a world map. Navigate through the markers to see details about each entry.\n\n## JSON Export\n\nUse the `json` command followed by a scrap ID to get the full JSON data for that specific scrap. This is useful for debugging or data export purposes.\n\n## Configuration\n\nScrapbook CLI uses environment variables for configuration. Create a `.env` file in your home directory with the following:\n\n```\nSUPABASE_URL=your_supabase_url\nSUPABASE_KEY=your_supabase_key\n```\n\n## Contributing\n\nPull requests are welcome. For major changes, please open an issue first to discuss what you would like to change.\n\n## License\n\n[MIT](https://choosealicense.com/licenses/mit/)\n\n## Acknowledgements\n\nBuilt with love, caffeine, and a dash of cyberpunk nostalgia. Special thanks to the creators of blessed, blessed-contrib, and Supabase for making this CLI possible.\n",
    "excerpt": "A cyberpunk-inspired, terminal-based interface for your digital scrapbook. Dive into your memories, search through your digital artifacts, and relive your onlin..."
  },
  "createdAt": "2024-06-01T07:35:15Z",
  "updatedAt": "2025-12-16T00:55:59Z",
  "pushedAt": "2025-12-16T00:55:56Z"
}