{
  "name": "vue-use-openrouter",
  "description": "No description provided",
  "url": "https://github.com/ejfox/vue-use-openrouter",
  "homepage": null,
  "stats": {
    "stars": 0,
    "forks": 0,
    "watchers": 1,
    "openIssues": 0
  },
  "language": "TypeScript",
  "languageColor": "#3178c6",
  "languages": {
    "TypeScript": 23793,
    "Vue": 588,
    "HTML": 351
  },
  "diskUsage": 238,
  "topics": [],
  "readme": {
    "html": "<h1 id=\"-useopenrouter\">ğŸ“¦ useOpenRouter</h1>\n<p>A Vue 3 composable for interacting with OpenRouter's AI models API. Easily integrate multiple AI models (like GPT-4, Claude, etc.) into your Vue applications.</p>\n<h2 id=\"-features\">ğŸŒŸ Features</h2>\n<ul>\n<li>ğŸ”Œ Simple integration with OpenRouter API</li>\n<li>ğŸ”„ Automatic model switching and management</li>\n<li>ğŸ’° Built-in cost tracking and token usage</li>\n<li>ğŸ§  Temperature control for response creativity</li>\n<li>ğŸ“ Full conversation history management</li>\n<li>ğŸ”’ Type-safe with full TypeScript support</li>\n<li>âš¡ Powered by Vue 3's Composition API</li>\n</ul>\n<h2 id=\"-installation\">ğŸ“¦ Installation</h2>\n<pre><code class=\"language-bash\"># npm\nnpm install use-openrouter\n\n# yarn\nyarn add use-openrouter\n\n# pnpm\npnpm add use-openrouter\n</code></pre>\n<h2 id=\"-quick-start\">ğŸš€ Quick Start</h2>\n<pre><code class=\"language-ts\">import { useOpenRouter } from 'use-openrouter'\n\n// Initialize with your API key\nconst chat = useOpenRouter({\n  apiKey: 'your-api-key',\n  defaultModel: 'anthropic/claude-3-sonnet'\n})\n\n// Send messages and get responses\nawait chat.sendMessage('What is quantum computing?')\nconsole.log(chat.messages.value.at(-1)?.content)\n\n// Track costs\nconsole.log(`Cost: $${chat.chatStats.value.totalCost}`)\n</code></pre>\n<h2 id=\"-usage-guide\">ğŸ“– Usage Guide</h2>\n<h3 id=\"basic-chat\">Basic Chat</h3>\n<pre><code class=\"language-ts\">const chat = useOpenRouter({ apiKey: 'your-api-key' })\n\n// Send a message\nawait chat.sendMessage('Hello AI!')\n\n// Get all messages\nconsole.log(chat.messages.value)\n// [\n//   { role: 'user', content: 'Hello AI!' },\n//   { role: 'assistant', content: 'Hello! How can I help...' }\n// ]\n</code></pre>\n<h3 id=\"switching-models\">Switching Models</h3>\n<pre><code class=\"language-ts\">// Get available models\nawait chat.fetchAvailableModels()\n\n// Switch to a different model\nchat.setModel('openai/gpt-4-turbo')\n\n// Check model costs\nconst cost = chat.formatModelCost(chat.currentModel.value)\nconsole.log(`This model costs ${cost} per million tokens`)\n</code></pre>\n<h3 id=\"temperature-control\">Temperature Control</h3>\n<pre><code class=\"language-ts\">// For creative tasks (more random)\nchat.updateTemperature(1.0)\nawait chat.sendMessage('Write a creative story')\n\n// For factual tasks (more focused)\nchat.updateTemperature(0.1)\nawait chat.sendMessage('What is 123 * 456?')\n</code></pre>\n<h3 id=\"cost-tracking\">Cost Tracking</h3>\n<pre><code class=\"language-ts\">// Track conversation costs\nconsole.log(chat.chatStats.value)\n// {\n//   tokens: 150,\n//   promptTokens: 50,\n//   completionTokens: 100,\n//   cost: 0.002,\n//   totalCost: 0.002\n// }\n\n// Format costs nicely\nconst cost = chat.formatModelCost('anthropic/claude-3-opus')\nconsole.log(cost) // \"$15.00\"\n</code></pre>\n<h3 id=\"error-handling\">Error Handling</h3>\n<pre><code class=\"language-ts\">try {\n  await chat.sendMessage('Hello')\n} catch (err) {\n  if (chat.error.value?.includes('401')) {\n    console.log('Invalid API key')\n  } else if (chat.error.value?.includes('429')) {\n    console.log('Rate limited - wait a bit')\n  }\n}\n</code></pre>\n<h2 id=\"ï¸-api-reference\">ğŸ› ï¸ API Reference</h2>\n<h3 id=\"configuration\">Configuration</h3>\n<pre><code class=\"language-ts\">interface OpenRouterOptions {\n  apiKey?: string          // Your OpenRouter API key\n  temperature?: number     // Initial temperature (0-1)\n  defaultModel?: string    // Starting model\n  enabledModels?: string[] // List of allowed models\n}\n</code></pre>\n<h3 id=\"properties\">Properties</h3>\n<ul>\n<li><code>messages</code> - Conversation history</li>\n<li><code>isLoading</code> - Request status</li>\n<li><code>error</code> - Error messages</li>\n<li><code>currentModel</code> - Active model ID</li>\n<li><code>modelName</code> - Active model display name</li>\n<li><code>chatStats</code> - Token and cost tracking</li>\n<li><code>temperature</code> - Current temperature setting</li>\n</ul>\n<h3 id=\"methods\">Methods</h3>\n<ul>\n<li><code>sendMessage(content: string)</code> - Send a message</li>\n<li><code>setModel(modelId: string)</code> - Switch models</li>\n<li><code>updateTemperature(value: number)</code> - Adjust temperature</li>\n<li><code>clearChat()</code> - Reset conversation</li>\n<li><code>fetchAvailableModels()</code> - Get model list</li>\n</ul>\n<h2 id=\"-license\">ğŸ“„ License</h2>\n<p>MIT License Â© 2024</p>\n<h2 id=\"-design-philosophy\">ğŸ’¡ Design Philosophy</h2>\n<p>We've carefully designed this composable to handle all the tricky parts of working with AI APIs:</p>\n<h3 id=\"ï¸-built-in-safeguards\">ğŸ›¡ï¸ Built-in Safeguards</h3>\n<ul>\n<li>Temperature is automatically clamped between 0-1</li>\n<li>Empty messages are rejected</li>\n<li>API key validation before requests</li>\n<li>Proper cleanup on component unmount</li>\n<li>SSR-safe window usage</li>\n</ul>\n<h3 id=\"-smart-cost-management\">ï¿½ï¿½ï¿½ï¿½ Smart Cost Management</h3>\n<ul>\n<li>Automatic token counting</li>\n<li>Running cost totals</li>\n<li>Smart decimal formatting (more decimals for cheap models)</li>\n<li>Cost-based model sorting (expensive â†’ cheap)</li>\n<li>Free model detection</li>\n</ul>\n<h3 id=\"-state-management\">ğŸ”„ State Management</h3>\n<ul>\n<li>Readonly refs where appropriate</li>\n<li>Automatic model fetching when API key changes</li>\n<li>Recent models tracking (last 10 used)</li>\n<li>Conversation history management</li>\n<li>Proper error state handling</li>\n</ul>\n<h3 id=\"-developer-experience\">ğŸ¯ Developer Experience</h3>\n<pre><code class=\"language-ts\">// Everything is typed!\nconst chat = useOpenRouter({\n  apiKey: 'key',\n  temperature: 0.7,\n  defaultModel: 'anthropic/claude-3-sonnet',\n  enabledModels: ['anthropic/claude-3-sonnet', 'openai/gpt-4']\n})\n\n// Costs are always formatted nicely\nchat.formatModelCost('openai/gpt-3.5-turbo') // \"$0.00200\"\nchat.formatModelCost('anthropic/claude-3-opus') // \"$15.00\"\n\n// Models are sorted by cost (expensive first)\nchat.enabledModels.value.forEach(model =&gt; {\n  console.log(`${model.name}: ${chat.formatModelCost(model.id)}`)\n})\n\n// Track all your costs\nconsole.log(chat.chatStats.value)\n// {\n//   tokens: 1500,\n//   promptTokens: 500,    // Input tokens\n//   completionTokens: 1000, // Output tokens\n//   cost: 0.015,          // Current conversation\n//   totalCost: 0.045      // All conversations\n// }\n</code></pre>\n<h3 id=\"-edge-cases-we-handle\">ğŸ” Edge Cases We Handle</h3>\n<ul>\n<li>Rate limiting detection</li>\n<li>Invalid API keys</li>\n<li>Empty or malformed responses</li>\n<li>Context length limits</li>\n<li>Model availability changes</li>\n<li>Token counting edge cases</li>\n<li>Cost calculation precision</li>\n<li>SSR compatibility</li>\n<li>Component unmounting</li>\n<li>Type safety throughout</li>\n</ul>\n<h3 id=\"-flexibility\">ğŸ¨ Flexibility</h3>\n<ul>\n<li>Use any OpenRouter model</li>\n<li>Customize temperature per request</li>\n<li>Track costs across conversations</li>\n<li>Enable/disable specific models</li>\n<li>Monitor token usage</li>\n<li>Handle errors your way</li>\n<li>Full TypeScript support</li>\n</ul>\n<p>We've aimed to create a composable that's both powerful and pleasant to use, handling all the complex bits while keeping the API clean and intuitive.</p>\n<h2 id=\"-documentation\">ğŸ“š Documentation</h2>\n<p>Full API documentation is available at <a href=\"https://your-username.github.io/use-openrouter/\">https://your-username.github.io/use-openrouter/</a></p>",
    "raw": "# ğŸ“¦ useOpenRouter\n\nA Vue 3 composable for interacting with OpenRouter's AI models API. Easily integrate multiple AI models (like GPT-4, Claude, etc.) into your Vue applications.\n\n## ğŸŒŸ Features\n\n- ğŸ”Œ Simple integration with OpenRouter API\n- ğŸ”„ Automatic model switching and management\n- ğŸ’° Built-in cost tracking and token usage\n- ğŸ§  Temperature control for response creativity\n- ğŸ“ Full conversation history management\n- ğŸ”’ Type-safe with full TypeScript support\n- âš¡ Powered by Vue 3's Composition API\n\n## ğŸ“¦ Installation\n\n```bash\n# npm\nnpm install use-openrouter\n\n# yarn\nyarn add use-openrouter\n\n# pnpm\npnpm add use-openrouter\n```\n\n## ğŸš€ Quick Start\n\n```ts\nimport { useOpenRouter } from 'use-openrouter'\n\n// Initialize with your API key\nconst chat = useOpenRouter({\n  apiKey: 'your-api-key',\n  defaultModel: 'anthropic/claude-3-sonnet'\n})\n\n// Send messages and get responses\nawait chat.sendMessage('What is quantum computing?')\nconsole.log(chat.messages.value.at(-1)?.content)\n\n// Track costs\nconsole.log(`Cost: $${chat.chatStats.value.totalCost}`)\n```\n\n## ğŸ“– Usage Guide\n\n### Basic Chat\n\n```ts\nconst chat = useOpenRouter({ apiKey: 'your-api-key' })\n\n// Send a message\nawait chat.sendMessage('Hello AI!')\n\n// Get all messages\nconsole.log(chat.messages.value)\n// [\n//   { role: 'user', content: 'Hello AI!' },\n//   { role: 'assistant', content: 'Hello! How can I help...' }\n// ]\n```\n\n### Switching Models\n\n```ts\n// Get available models\nawait chat.fetchAvailableModels()\n\n// Switch to a different model\nchat.setModel('openai/gpt-4-turbo')\n\n// Check model costs\nconst cost = chat.formatModelCost(chat.currentModel.value)\nconsole.log(`This model costs ${cost} per million tokens`)\n```\n\n### Temperature Control\n\n```ts\n// For creative tasks (more random)\nchat.updateTemperature(1.0)\nawait chat.sendMessage('Write a creative story')\n\n// For factual tasks (more focused)\nchat.updateTemperature(0.1)\nawait chat.sendMessage('What is 123 * 456?')\n```\n\n### Cost Tracking\n\n```ts\n// Track conversation costs\nconsole.log(chat.chatStats.value)\n// {\n//   tokens: 150,\n//   promptTokens: 50,\n//   completionTokens: 100,\n//   cost: 0.002,\n//   totalCost: 0.002\n// }\n\n// Format costs nicely\nconst cost = chat.formatModelCost('anthropic/claude-3-opus')\nconsole.log(cost) // \"$15.00\"\n```\n\n### Error Handling\n\n```ts\ntry {\n  await chat.sendMessage('Hello')\n} catch (err) {\n  if (chat.error.value?.includes('401')) {\n    console.log('Invalid API key')\n  } else if (chat.error.value?.includes('429')) {\n    console.log('Rate limited - wait a bit')\n  }\n}\n```\n\n## ğŸ› ï¸ API Reference\n\n### Configuration\n\n```ts\ninterface OpenRouterOptions {\n  apiKey?: string          // Your OpenRouter API key\n  temperature?: number     // Initial temperature (0-1)\n  defaultModel?: string    // Starting model\n  enabledModels?: string[] // List of allowed models\n}\n```\n\n### Properties\n\n- `messages` - Conversation history\n- `isLoading` - Request status\n- `error` - Error messages\n- `currentModel` - Active model ID\n- `modelName` - Active model display name\n- `chatStats` - Token and cost tracking\n- `temperature` - Current temperature setting\n\n### Methods\n\n- `sendMessage(content: string)` - Send a message\n- `setModel(modelId: string)` - Switch models\n- `updateTemperature(value: number)` - Adjust temperature\n- `clearChat()` - Reset conversation\n- `fetchAvailableModels()` - Get model list\n\n## ğŸ“„ License\n\nMIT License Â© 2024\n\n## ğŸ’¡ Design Philosophy\n\nWe've carefully designed this composable to handle all the tricky parts of working with AI APIs:\n\n### ğŸ›¡ï¸ Built-in Safeguards\n\n- Temperature is automatically clamped between 0-1\n- Empty messages are rejected\n- API key validation before requests\n- Proper cleanup on component unmount\n- SSR-safe window usage\n\n### ï¿½ï¿½ï¿½ï¿½ Smart Cost Management\n\n- Automatic token counting\n- Running cost totals\n- Smart decimal formatting (more decimals for cheap models)\n- Cost-based model sorting (expensive â†’ cheap)\n- Free model detection\n\n### ğŸ”„ State Management\n\n- Readonly refs where appropriate\n- Automatic model fetching when API key changes\n- Recent models tracking (last 10 used)\n- Conversation history management\n- Proper error state handling\n\n### ğŸ¯ Developer Experience\n\n```ts\n// Everything is typed!\nconst chat = useOpenRouter({\n  apiKey: 'key',\n  temperature: 0.7,\n  defaultModel: 'anthropic/claude-3-sonnet',\n  enabledModels: ['anthropic/claude-3-sonnet', 'openai/gpt-4']\n})\n\n// Costs are always formatted nicely\nchat.formatModelCost('openai/gpt-3.5-turbo') // \"$0.00200\"\nchat.formatModelCost('anthropic/claude-3-opus') // \"$15.00\"\n\n// Models are sorted by cost (expensive first)\nchat.enabledModels.value.forEach(model => {\n  console.log(`${model.name}: ${chat.formatModelCost(model.id)}`)\n})\n\n// Track all your costs\nconsole.log(chat.chatStats.value)\n// {\n//   tokens: 1500,\n//   promptTokens: 500,    // Input tokens\n//   completionTokens: 1000, // Output tokens\n//   cost: 0.015,          // Current conversation\n//   totalCost: 0.045      // All conversations\n// }\n```\n\n### ğŸ” Edge Cases We Handle\n\n- Rate limiting detection\n- Invalid API keys\n- Empty or malformed responses\n- Context length limits\n- Model availability changes\n- Token counting edge cases\n- Cost calculation precision\n- SSR compatibility\n- Component unmounting\n- Type safety throughout\n\n### ğŸ¨ Flexibility\n\n- Use any OpenRouter model\n- Customize temperature per request\n- Track costs across conversations\n- Enable/disable specific models\n- Monitor token usage\n- Handle errors your way\n- Full TypeScript support\n\nWe've aimed to create a composable that's both powerful and pleasant to use, handling all the complex bits while keeping the API clean and intuitive.\n\n## ğŸ“š Documentation\n\nFull API documentation is available at [https://your-username.github.io/use-openrouter/](https://your-username.github.io/use-openrouter/)\n",
    "excerpt": "A Vue 3 composable for interacting with OpenRouter's AI models API. Easily integrate multiple AI models (like GPT-4, Claude, etc.) into your Vue applications...."
  },
  "createdAt": "2024-12-08T02:54:30Z",
  "updatedAt": "2024-12-08T05:18:39Z",
  "pushedAt": "2024-12-08T05:18:35Z"
}