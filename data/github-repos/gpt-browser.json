{
  "name": "gpt-browser",
  "description": "A Node.js script utilizing OpenAI's GPT to fetch, parse, and succinctly summarize web pages. ",
  "url": "https://github.com/ejfox/gpt-browser",
  "homepage": null,
  "stats": {
    "stars": 5,
    "forks": 0,
    "watchers": 2,
    "openIssues": 0
  },
  "language": "JavaScript",
  "languageColor": "#f1e05a",
  "topics": [],
  "readme": {
    "html": "<h1 id=\"gpt-browser\">GPT Browser</h1>\n<p>A powerful Node.js package that fetches a webpage, breaks it into chunks, analyzes its content, and generates a summary using OpenAI's Chat API.</p>\n<p><a href=\"https://github.com/ejfox/gpt-browser/assets/530073/e7a5a81e-40ca-44fb-8d2d-a1b0daa235b5\">https://github.com/ejfox/gpt-browser/assets/530073/e7a5a81e-40ca-44fb-8d2d-a1b0daa235b5</a></p>\n<h2 id=\"features\">Features</h2>\n<ul>\n<li>Fetches and parses webpages using Puppeteer</li>\n<li>Generates summaries using OpenAI's Chat API</li>\n<li>Customizable summarization options (model, prompts, token limits)</li>\n<li>Easy integration into your Node.js projects</li>\n<li>Command-line interface using <code>npx</code></li>\n</ul>\n<h2 id=\"installation\">Installation</h2>\n<p>To use GPT Browser in your project, install it from npm:</p>\n<pre><code class=\"language-bash\">npm install @ejfox/gpt-browser\n</code></pre>\n<h2 id=\"usage\">Usage</h2>\n<h3 id=\"in-a-nodejs-project\">In a Node.js Project</h3>\n<p>Import the <code>fetchAndSummarizeUrl</code> function from the package and use it in your code:</p>\n<pre><code class=\"language-javascript\">const { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://example.com';\n  const options = {\n    model: 'gpt-3.5-turbo',\n    summaryPrompt: 'Summarize the key points from the webpage:',\n  };\n\n  const summary = await fetchAndSummarizeUrl(url, options);\n  console.log(summary);\n}\n\nmain();\n</code></pre>\n<h3 id=\"using-npx\">Using <code>npx</code></h3>\n<p>You can also use GPT Browser directly from the command line using <code>npx</code>:</p>\n<pre><code class=\"language-bash\">npx @ejfox/gpt-browser --url https://example.com\n</code></pre>\n<h4 id=\"customization-options\">Customization Options</h4>\n<p>You can customize the summarization process by passing additional options:</p>\n<ul>\n<li><code>--model</code> or <code>-m</code>: OpenAI model to use for summarization (default: \"gpt-4-turbo-preview\")</li>\n<li><code>--chunkAmount</code> or <code>-c</code>: Desired chunk size for text splitting (default: 12952)</li>\n<li><code>--summaryPrompt</code> or <code>-sp</code>: Prompt for generating the summary (default: \"Please sort these facts from in order of importance, with the most important fact first\")</li>\n<li><code>--summaryMaxTokens</code> or <code>-smt</code>: Maximum number of tokens for the summary (default: 4096)</li>\n<li><code>--chunkPrompt</code> or <code>-cp</code>: Prompt for processing text chunks (default: WEBPAGE_UNDERSTANDER_PROMPT)</li>\n</ul>\n<p>Example with custom options:</p>\n<pre><code class=\"language-bash\">npx @ejfox/gpt-browser --url https://example.com --model gpt-3.5-turbo --chunkAmount 8000 --summaryPrompt \"Summarize the key points from the webpage:\"\n</code></pre>\n<p>You can also store your prompts in local text files and echo them into the command:</p>\n<pre><code class=\"language-bash\">npx @ejfox/gpt-browser --url https://example.com --summaryPrompt \"$(cat summaryprompt1.txt)\" --chunkPrompt \"$(cat chunkprompt2.txt)\"\n</code></pre>\n<h2 id=\"examples\">Examples</h2>\n<ol>\n<li>Summarize a Wikipedia article in your Node.js project:</li>\n</ol>\n<pre><code class=\"language-javascript\">const { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://en.wikipedia.org/wiki/OpenAI';\n  const summary = await fetchAndSummarizeUrl(url);\n  console.log(summary);\n}\n\nmain();\n</code></pre>\n<ol>\n<li>Summarize a news article with a custom prompt using <code>npx</code>:</li>\n</ol>\n<pre><code class=\"language-bash\">npx @ejfox/gpt-browser --url https://www.theatlantic.com/science/archive/2024/02/talking-whales-project-ceti --summaryPrompt \"Provide a brief overview of the main events covered in the article:\"\n</code></pre>\n<ol>\n<li>Summarize a blog post using a different OpenAI model in your project:</li>\n</ol>\n<pre><code class=\"language-javascript\">const { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://openai.com/blog/chatgpt';\n  const options = {\n    model: 'gpt-3.5-turbo',\n  };\n\n  const summary = await fetchAndSummarizeUrl(url, options);\n  console.log(summary);\n}\n\nmain();\n</code></pre>\n<h2 id=\"license\">License</h2>\n<p>This project is open-source and available under the <a href=\"LICENSE\">MIT License</a>.</p>",
    "raw": "# GPT Browser\n\nA powerful Node.js package that fetches a webpage, breaks it into chunks, analyzes its content, and generates a summary using OpenAI's Chat API.\n\n\n\nhttps://github.com/ejfox/gpt-browser/assets/530073/e7a5a81e-40ca-44fb-8d2d-a1b0daa235b5\n\n\n\n## Features\n\n- Fetches and parses webpages using Puppeteer\n- Generates summaries using OpenAI's Chat API\n- Customizable summarization options (model, prompts, token limits)\n- Easy integration into your Node.js projects\n- Command-line interface using `npx`\n\n## Installation\n\nTo use GPT Browser in your project, install it from npm:\n\n```bash\nnpm install @ejfox/gpt-browser\n```\n\n## Usage\n\n### In a Node.js Project\n\nImport the `fetchAndSummarizeUrl` function from the package and use it in your code:\n\n```javascript\nconst { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://example.com';\n  const options = {\n    model: 'gpt-3.5-turbo',\n    summaryPrompt: 'Summarize the key points from the webpage:',\n  };\n\n  const summary = await fetchAndSummarizeUrl(url, options);\n  console.log(summary);\n}\n\nmain();\n```\n\n### Using `npx`\n\nYou can also use GPT Browser directly from the command line using `npx`:\n\n```bash\nnpx @ejfox/gpt-browser --url https://example.com\n```\n\n#### Customization Options\n\nYou can customize the summarization process by passing additional options:\n\n- `--model` or `-m`: OpenAI model to use for summarization (default: \"gpt-4-turbo-preview\")\n- `--chunkAmount` or `-c`: Desired chunk size for text splitting (default: 12952)\n- `--summaryPrompt` or `-sp`: Prompt for generating the summary (default: \"Please sort these facts from in order of importance, with the most important fact first\")\n- `--summaryMaxTokens` or `-smt`: Maximum number of tokens for the summary (default: 4096)\n- `--chunkPrompt` or `-cp`: Prompt for processing text chunks (default: WEBPAGE_UNDERSTANDER_PROMPT)\n\nExample with custom options:\n\n```bash\nnpx @ejfox/gpt-browser --url https://example.com --model gpt-3.5-turbo --chunkAmount 8000 --summaryPrompt \"Summarize the key points from the webpage:\"\n```\n\nYou can also store your prompts in local text files and echo them into the command:\n\n```bash\nnpx @ejfox/gpt-browser --url https://example.com --summaryPrompt \"$(cat summaryprompt1.txt)\" --chunkPrompt \"$(cat chunkprompt2.txt)\"\n```\n\n## Examples\n\n1. Summarize a Wikipedia article in your Node.js project:\n\n```javascript\nconst { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://en.wikipedia.org/wiki/OpenAI';\n  const summary = await fetchAndSummarizeUrl(url);\n  console.log(summary);\n}\n\nmain();\n```\n\n2. Summarize a news article with a custom prompt using `npx`:\n\n```bash\nnpx @ejfox/gpt-browser --url https://www.theatlantic.com/science/archive/2024/02/talking-whales-project-ceti --summaryPrompt \"Provide a brief overview of the main events covered in the article:\"\n```\n\n3. Summarize a blog post using a different OpenAI model in your project:\n\n```javascript\nconst { fetchAndSummarizeUrl } = require('@ejfox/gpt-browser');\n\nasync function main() {\n  const url = 'https://openai.com/blog/chatgpt';\n  const options = {\n    model: 'gpt-3.5-turbo',\n  };\n\n  const summary = await fetchAndSummarizeUrl(url, options);\n  console.log(summary);\n}\n\nmain();\n```\n\n## License\n\nThis project is open-source and available under the [MIT License](LICENSE).\n",
    "excerpt": "A powerful Node.js package that fetches a webpage, breaks it into chunks, analyzes its content, and generates a summary using OpenAI's Chat API.\n\n\n\nhttps://gith..."
  },
  "createdAt": "2023-07-14T19:13:24Z",
  "updatedAt": "2025-03-07T00:30:23Z",
  "pushedAt": "2024-05-22T04:57:01Z"
}